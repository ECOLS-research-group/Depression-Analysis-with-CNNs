# -*- coding: utf-8 -*-
"""bert_hybrid_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gN7kPjJ0SmJ88X1FbEDuey5Xdbu5r2X0

### **DATA LOADING**
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Path to your file on Google Drive
file_path = "/content/drive/My Drive/merged_tensors_with_labels.csv"

# Copy the file to Colab under the /content directory
!cp "{file_path}" /content

# Load the CSV file into a DataFrame
import pandas as pd
df = pd.read_csv("/content/merged_tensors_with_labels.csv")

# Display the DataFrame
print(df.head())

"""---

## **LSTM**
"""

!pip install tensorflow

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

# Load the dataset
file_path = 'merged_tensors_with_labels.csv'  # Update the path as needed
df = pd.read_csv(file_path)

# Preprocess the data
X = df.iloc[:, :-1].values  # Features are all columns except the last one (BERT-encoded vectors)
y = df['is_depression'].values  # Labels (target variable)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape the input data for LSTM
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build the LSTM model
model = Sequential()
model.add(LSTM(128, input_shape=(X_train.shape[1], 1), return_sequences=True))
model.add(Dropout(0.5))
model.add(LSTM(64))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model on the test data
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')

# Predict on the test set
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

# Calculate ROC AUC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)
print(f'AUC: {roc_auc}')

# Plot ROC curve with 300 DPI
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.savefig('roc_curve.png', dpi=300)  # Save the figure with 300 DPI
plt.show()

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Plot confusion matrix for the test set
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Depression', 'Depression'], yticklabels=['Non-Depression', 'Depression'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix.png', dpi=300)  # Save the figure with 300 DPI
plt.show()

# Optional: Plot training history (accuracy and loss curves)
plt.figure(figsize=(12, 6))

# Plot training & validation accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plot training & validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.savefig('training_history.png', dpi=300)  # Save the figure with 300 DPI
plt.show()

"""---

# **RANDOM FOREST**
"""

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
from sklearn.inspection import PartialDependenceDisplay
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
file_path = 'merged_tensors_with_labels.csv'  # Update the path as needed
df = pd.read_csv(file_path)

# Preprocess the data
X = df.iloc[:, :-1].values  # Features are all columns except the last one (BERT-encoded vectors)
y = df['is_depression'].values  # Labels (target variable)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Predict on the test set
y_pred = rf_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Test Accuracy: {accuracy:.4f}')

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Plot confusion matrix for the test set
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Depression', 'Depression'], yticklabels=['Non-Depression', 'Depression'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Calculate ROC AUC
y_pred_prob = rf_model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)
print(f'AUC: {roc_auc}')

# Plot ROC curve
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Feature Importance
importances = rf_model.feature_importances_
plt.figure(figsize=(10, 6))
plt.bar(range(X.shape[1]), importances, align='center')
plt.xlabel('Feature Index')
plt.ylabel('Feature Importance')
plt.title('Feature Importances from Random Forest')
plt.show()

# Partial Dependence Plots (PDP) for top 3 features
top_features = np.argsort(importances)[-3:]
fig, ax = plt.subplots(figsize=(10, 6))
PartialDependenceDisplay.from_estimator(rf_model, X_train, top_features, ax=ax)
plt.suptitle('Partial Dependence Plots for Top 3 Features', fontsize=14)
plt.subplots_adjust(top=0.9)  # Adjust layout to ensure title is centered
plt.show()

# Learning Curves
train_sizes, train_scores, test_scores = learning_curve(rf_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))

train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, label='Training Score', color='blue', marker='o')
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')
plt.plot(train_sizes, test_mean, label='Cross-Validation Score', color='green', marker='o')
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.15, color='green')
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy Score')
plt.title('Learning Curves')
plt.legend(loc='best')
plt.grid()
plt.show()

"""# **Support Vector Machine (SVM)**"""

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
file_path = 'merged_tensors_with_labels.csv'  # Update the path as needed
df = pd.read_csv(file_path)

# Preprocess the data
X = df.iloc[:, :-1].values  # Features are all columns except the last one (BERT-encoded vectors)
y = df['is_depression'].values  # Labels (target variable)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the SVM model (using Radial Basis Function (RBF) kernel)
svm_model = SVC(kernel='rbf', probability=True, random_state=42)

# Train the model
svm_model.fit(X_train, y_train)

# Predict on the test set
y_pred = svm_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Test Accuracy: {accuracy:.4f}')

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Plot confusion matrix for the test set
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Depression', 'Depression'], yticklabels=['Non-Depression', 'Depression'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Calculate ROC AUC
y_pred_prob = svm_model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)
print(f'AUC: {roc_auc}')

# Plot ROC curve
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

!pip install shap

# ================================
# Import required libraries
# ================================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt
import shap
import os

# ================================
# Create output folder
# ================================
os.makedirs("explainability_plots", exist_ok=True)

# ================================
# Load dataset
# ================================
file_path = 'merged_tensors_with_labels.csv'  # Update as needed
df = pd.read_csv(file_path)

X = df.iloc[:, :-1].values
y = df['is_depression'].values

# ================================
# Train-test split
# ================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ================================
# Train linear SVM (hSVM)
# ================================
svm_model = SVC(kernel='linear', probability=True, random_state=42)
svm_model.fit(X_train, y_train)

# Predictions
y_pred = svm_model.predict(X_test)

# ================================
# Confusion Matrix
# ================================
conf_mat = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Non-Depression', 'Depression'],
            yticklabels=['Non-Depression', 'Depression'])
plt.title('Confusion Matrix – hSVM')
plt.tight_layout()
plt.savefig("explainability_plots/hsvm_confusion_matrix.png", dpi=300)
plt.close()

# ================================
# SHAP Explainability
# ================================
shap_explainer = shap.Explainer(svm_model, X_train)  # <-- FIXED
shap_values = shap_explainer(X_test)

# SHAP summary plot
shap.summary_plot(shap_values, X_test, show=False)
plt.tight_layout()
plt.savefig("explainability_plots/hsvm_shap_summary.png", dpi=300, bbox_inches='tight')
plt.close()

# SHAP local: correct depressive prediction
correct_idx = np.where((y_test == 1) & (y_pred == 1))[0][0]
shap.plots.waterfall(shap_values[correct_idx], show=False)
plt.title("Correct Depressive Classification – SHAP")
plt.tight_layout()
plt.savefig("explainability_plots/hsvm_shap_correct.png", dpi=300, bbox_inches='tight')
plt.close()

# SHAP local: false negative
incorrect_idx = np.where((y_test == 1) & (y_pred == 0))[0][0]
shap.plots.waterfall(shap_values[incorrect_idx], show=False)
plt.title("False Negative Example – SHAP")
plt.tight_layout()
plt.savefig("explainability_plots/hsvm_shap_false_negative.png", dpi=300, bbox_inches='tight')
plt.close()

print("✅ Explainability plots for Reviewer #7 saved in 'explainability_plots/'")

"""# **1D CNN**"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from hyperopt import fmin, tpe, hp, Trials, STATUS_OK

# Load the dataset
file_path = "merged_tensors_with_labels.csv"
df = pd.read_csv(file_path)

# Preprocess the data
X = df.iloc[:, :-1].values  # Features (encoded vectors from BERT)
y = df['is_depression'].values  # Labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape input for 1D CNN
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Hyperparameter space for tuning
space = {
    'filters': hp.choice('filters', [32, 64, 128]),
    'kernel_size': hp.quniform('kernel_size', 3, 9, 2),
    'pool_size': hp.quniform('pool_size', 2, 4, 1),
    'dense_units': hp.quniform('dense_units', 64, 256, 32),
    'dropout': hp.uniform('dropout', 0.1, 0.5),
    'batch_size': hp.choice('batch_size', [16, 32, 64]),
    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2))
}

# Model creation function for tuning
def create_and_evaluate(params):
    model = Sequential()
    model.add(Conv1D(
        filters=int(params['filters']),
        kernel_size=int(params['kernel_size']),
        activation='relu',
        input_shape=(X_train.shape[1], 1)
    ))
    model.add(MaxPooling1D(pool_size=int(params['pool_size'])))
    model.add(Flatten())
    model.add(Dense(int(params['dense_units']), activation='relu'))
    model.add(Dropout(params['dropout']))
    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer=Adam(learning_rate=params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])

    history = model.fit(
        X_train, y_train,
        epochs=10,
        batch_size=int(params['batch_size']),
        verbose=0,
        validation_split=0.2
    )

    val_loss, val_accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"Validation Accuracy: {val_accuracy}")
    return {'loss': -val_accuracy, 'status': STATUS_OK}

# Bayesian Optimization
trials = Trials()
best_params = fmin(
    fn=create_and_evaluate,
    space=space,
    algo=tpe.suggest,
    max_evals=10,
    trials=trials
)

# Extract best hyperparameters
best_params['kernel_size'] = int(best_params['kernel_size'])
best_params['pool_size'] = int(best_params['pool_size'])
best_params['dense_units'] = int(best_params['dense_units'])
best_params['batch_size'] = [16, 32, 64][best_params['batch_size']]
best_params['filters'] = [32, 64, 128][best_params['filters']]
print(f"Best Hyperparameters: {best_params}")

# Final Model Training with Best Parameters
final_model = Sequential()
final_model.add(Conv1D(
    filters=best_params['filters'],
    kernel_size=best_params['kernel_size'],
    activation='relu',
    input_shape=(X_train.shape[1], 1)
))
final_model.add(MaxPooling1D(pool_size=best_params['pool_size']))
final_model.add(Flatten())
final_model.add(Dense(best_params['dense_units'], activation='relu'))
final_model.add(Dropout(best_params['dropout']))
final_model.add(Dense(1, activation='sigmoid'))

final_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])

history = final_model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=best_params['batch_size'],
    validation_split=0.2
)

# Evaluate on Test Set
loss, accuracy = final_model.evaluate(X_test, y_test)
print(f"Final Test Loss: {loss:.4f}, Final Test Accuracy: {accuracy:.4f}")

# Predictions and Metrics
y_pred_prob = final_model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

# Classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Depression', 'Depression'], yticklabels=['Non-Depression', 'Depression'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()