{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b29dba5a4fac47d1aa56c2625183428e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc7b9f04eebb4b9ea8609b4b8d0e0a39",
              "IPY_MODEL_2547ea8ddcbc4dc9ac763d537a3c897f",
              "IPY_MODEL_50dcb100e2a741c3907dfc6f478c096e"
            ],
            "layout": "IPY_MODEL_06826ee365fc460fbc17daf9c85d7871"
          }
        },
        "cc7b9f04eebb4b9ea8609b4b8d0e0a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30ffe0758b44881935bf518f7d953c5",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d36214fc88422fbb3d7432b7b00bd9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2547ea8ddcbc4dc9ac763d537a3c897f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43975ca3bef64d7d9e999aa4013fa617",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57ba0ee3372744108d84663d42c43fd9",
            "value": 48
          }
        },
        "50dcb100e2a741c3907dfc6f478c096e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53f7c39676840b2af1a115565b06ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_10a709668cc74c0191841d7b81fd7d56",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.34kB/s]"
          }
        },
        "06826ee365fc460fbc17daf9c85d7871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30ffe0758b44881935bf518f7d953c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d36214fc88422fbb3d7432b7b00bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43975ca3bef64d7d9e999aa4013fa617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ba0ee3372744108d84663d42c43fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e53f7c39676840b2af1a115565b06ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a709668cc74c0191841d7b81fd7d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53762dc1f8ff43968516f6d630e4bc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67921d1efee5468fb55db598289232f2",
              "IPY_MODEL_635aa0a6da6d4ca2a764a9ed69e3ad17",
              "IPY_MODEL_d4f75a819ea140e682ea235f5db7b3d4"
            ],
            "layout": "IPY_MODEL_1a97e6e847cc4ea7bdaf6851855dd0ba"
          }
        },
        "67921d1efee5468fb55db598289232f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b297086a323c4754962b84acd76068c4",
            "placeholder": "​",
            "style": "IPY_MODEL_58c4243caf104566b48628c321a8c980",
            "value": "vocab.txt: 100%"
          }
        },
        "635aa0a6da6d4ca2a764a9ed69e3ad17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8256a91b2f3e493e8dafe13fd8414538",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6a47faf868c4dbb9de43dc7e659db02",
            "value": 231508
          }
        },
        "d4f75a819ea140e682ea235f5db7b3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b823d593b145a5a56f543d50049cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_3389b8d7d34e46bd96900de080caee4f",
            "value": " 232k/232k [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "1a97e6e847cc4ea7bdaf6851855dd0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b297086a323c4754962b84acd76068c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c4243caf104566b48628c321a8c980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8256a91b2f3e493e8dafe13fd8414538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a47faf868c4dbb9de43dc7e659db02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84b823d593b145a5a56f543d50049cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3389b8d7d34e46bd96900de080caee4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087f274ccaae457d911089392c0c949e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d9d6bcdd2b84eadac5d5db43a6e7ead",
              "IPY_MODEL_5abd2ebc81ca4902899a299810630e5e",
              "IPY_MODEL_9d520b6d22d44bf9b2b568828c8cb424"
            ],
            "layout": "IPY_MODEL_65333e833c95493988a6b37a2c3a70ad"
          }
        },
        "9d9d6bcdd2b84eadac5d5db43a6e7ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f4a18a6c404c39ad3bf01d5f624e36",
            "placeholder": "​",
            "style": "IPY_MODEL_5f6b88f3549c4cae8c35c2b27be75206",
            "value": "tokenizer.json: 100%"
          }
        },
        "5abd2ebc81ca4902899a299810630e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce6210c5a5e4bbf97bc0d306e615e2f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d04bbde4c94e4a8780b6ddc54a2d1aa5",
            "value": 466062
          }
        },
        "9d520b6d22d44bf9b2b568828c8cb424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eea3cf6ede84ede83d0667bddf7ca4c",
            "placeholder": "​",
            "style": "IPY_MODEL_f20041aa83d94a60940ac0aedee81411",
            "value": " 466k/466k [00:00&lt;00:00, 23.0MB/s]"
          }
        },
        "65333e833c95493988a6b37a2c3a70ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f4a18a6c404c39ad3bf01d5f624e36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6b88f3549c4cae8c35c2b27be75206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce6210c5a5e4bbf97bc0d306e615e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d04bbde4c94e4a8780b6ddc54a2d1aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eea3cf6ede84ede83d0667bddf7ca4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20041aa83d94a60940ac0aedee81411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5cec9cc3b554f949d5566e6125ccaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_392964d6056749cea1ace62327acf497",
              "IPY_MODEL_ed63c75d2975447eb6a6533f7befc24c",
              "IPY_MODEL_efb73a35a2874f019e45dc466b939267"
            ],
            "layout": "IPY_MODEL_c853235220984c5cae1ef5f1a2decb22"
          }
        },
        "392964d6056749cea1ace62327acf497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c945832e9a481e915f4f347aabee4b",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd98f25b0be496c8413270a3a48f823",
            "value": "config.json: 100%"
          }
        },
        "ed63c75d2975447eb6a6533f7befc24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889821b2be904404aa5a06a73fcaa4c2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2167525586dd428a940d13cb0fe13016",
            "value": 570
          }
        },
        "efb73a35a2874f019e45dc466b939267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b595038ade734b1fbe6ec85c3ae1db15",
            "placeholder": "​",
            "style": "IPY_MODEL_bfd64ae42aa54d929e4bd45cb1c41d0c",
            "value": " 570/570 [00:00&lt;00:00, 41.7kB/s]"
          }
        },
        "c853235220984c5cae1ef5f1a2decb22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c945832e9a481e915f4f347aabee4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd98f25b0be496c8413270a3a48f823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889821b2be904404aa5a06a73fcaa4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2167525586dd428a940d13cb0fe13016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b595038ade734b1fbe6ec85c3ae1db15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd64ae42aa54d929e4bd45cb1c41d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06ef862fa15a4d49b81452af301e2699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39a373f681734943becada4f27e0a9a8",
              "IPY_MODEL_1185ca3bfd544477b24dc6b28cba84ac",
              "IPY_MODEL_1cdc84f7b3de42479cb2879a14b478e4"
            ],
            "layout": "IPY_MODEL_0364d57a41d74fca8d9611b7f68cd22c"
          }
        },
        "39a373f681734943becada4f27e0a9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a378530b0d64a58882582655979beab",
            "placeholder": "​",
            "style": "IPY_MODEL_aa841c0272f947148bbfff1eb48aac04",
            "value": "model.safetensors: 100%"
          }
        },
        "1185ca3bfd544477b24dc6b28cba84ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05840e737cba4f3eabb6113aff972413",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_570b53d6fe934da583e5ee05bb32530f",
            "value": 440449768
          }
        },
        "1cdc84f7b3de42479cb2879a14b478e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d87bc47ef448d5b4e669e704592c49",
            "placeholder": "​",
            "style": "IPY_MODEL_4300caad962d42a99eb16ae407a9ab46",
            "value": " 440M/440M [00:01&lt;00:00, 250MB/s]"
          }
        },
        "0364d57a41d74fca8d9611b7f68cd22c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a378530b0d64a58882582655979beab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa841c0272f947148bbfff1eb48aac04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05840e737cba4f3eabb6113aff972413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570b53d6fe934da583e5ee05bb32530f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1d87bc47ef448d5b4e669e704592c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4300caad962d42a99eb16ae407a9ab46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b29dba5a4fac47d1aa56c2625183428e",
            "cc7b9f04eebb4b9ea8609b4b8d0e0a39",
            "2547ea8ddcbc4dc9ac763d537a3c897f",
            "50dcb100e2a741c3907dfc6f478c096e",
            "06826ee365fc460fbc17daf9c85d7871",
            "e30ffe0758b44881935bf518f7d953c5",
            "d9d36214fc88422fbb3d7432b7b00bd9",
            "43975ca3bef64d7d9e999aa4013fa617",
            "57ba0ee3372744108d84663d42c43fd9",
            "e53f7c39676840b2af1a115565b06ae6",
            "10a709668cc74c0191841d7b81fd7d56",
            "53762dc1f8ff43968516f6d630e4bc47",
            "67921d1efee5468fb55db598289232f2",
            "635aa0a6da6d4ca2a764a9ed69e3ad17",
            "d4f75a819ea140e682ea235f5db7b3d4",
            "1a97e6e847cc4ea7bdaf6851855dd0ba",
            "b297086a323c4754962b84acd76068c4",
            "58c4243caf104566b48628c321a8c980",
            "8256a91b2f3e493e8dafe13fd8414538",
            "f6a47faf868c4dbb9de43dc7e659db02",
            "84b823d593b145a5a56f543d50049cf8",
            "3389b8d7d34e46bd96900de080caee4f",
            "087f274ccaae457d911089392c0c949e",
            "9d9d6bcdd2b84eadac5d5db43a6e7ead",
            "5abd2ebc81ca4902899a299810630e5e",
            "9d520b6d22d44bf9b2b568828c8cb424",
            "65333e833c95493988a6b37a2c3a70ad",
            "e4f4a18a6c404c39ad3bf01d5f624e36",
            "5f6b88f3549c4cae8c35c2b27be75206",
            "bce6210c5a5e4bbf97bc0d306e615e2f",
            "d04bbde4c94e4a8780b6ddc54a2d1aa5",
            "7eea3cf6ede84ede83d0667bddf7ca4c",
            "f20041aa83d94a60940ac0aedee81411",
            "c5cec9cc3b554f949d5566e6125ccaad",
            "392964d6056749cea1ace62327acf497",
            "ed63c75d2975447eb6a6533f7befc24c",
            "efb73a35a2874f019e45dc466b939267",
            "c853235220984c5cae1ef5f1a2decb22",
            "43c945832e9a481e915f4f347aabee4b",
            "4cd98f25b0be496c8413270a3a48f823",
            "889821b2be904404aa5a06a73fcaa4c2",
            "2167525586dd428a940d13cb0fe13016",
            "b595038ade734b1fbe6ec85c3ae1db15",
            "bfd64ae42aa54d929e4bd45cb1c41d0c",
            "06ef862fa15a4d49b81452af301e2699",
            "39a373f681734943becada4f27e0a9a8",
            "1185ca3bfd544477b24dc6b28cba84ac",
            "1cdc84f7b3de42479cb2879a14b478e4",
            "0364d57a41d74fca8d9611b7f68cd22c",
            "2a378530b0d64a58882582655979beab",
            "aa841c0272f947148bbfff1eb48aac04",
            "05840e737cba4f3eabb6113aff972413",
            "570b53d6fe934da583e5ee05bb32530f",
            "d1d87bc47ef448d5b4e669e704592c49",
            "4300caad962d42a99eb16ae407a9ab46"
          ]
        },
        "id": "KkrizOR02nsO",
        "outputId": "b4678dcf-814e-4471-d5e1-602338922fb6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: NVIDIA L4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b29dba5a4fac47d1aa56c2625183428e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53762dc1f8ff43968516f6d630e4bc47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "087f274ccaae457d911089392c0c949e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5cec9cc3b554f949d5566e6125ccaad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06ef862fa15a4d49b81452af301e2699",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.666797   |     -      |     -     |   4.59   \n",
            "   1    |   40    |   0.574144   |     -      |     -     |   3.26   \n",
            "   1    |   60    |   0.548386   |     -      |     -     |   3.27   \n",
            "   1    |   80    |   0.519981   |     -      |     -     |   3.28   \n",
            "   1    |   100   |   0.533494   |     -      |     -     |   3.30   \n",
            "   1    |   120   |   0.419828   |     -      |     -     |   3.29   \n",
            "   1    |   140   |   0.455816   |     -      |     -     |   3.30   \n",
            "   1    |   160   |   0.433959   |     -      |     -     |   3.32   \n",
            "   1    |   180   |   0.466867   |     -      |     -     |   3.32   \n",
            "   1    |   200   |   0.437876   |     -      |     -     |   3.33   \n",
            "   1    |   220   |   0.454586   |     -      |     -     |   3.33   \n",
            "   1    |   240   |   0.390583   |     -      |     -     |   3.34   \n",
            "   1    |   260   |   0.431993   |     -      |     -     |   3.35   \n",
            "   1    |   280   |   0.451767   |     -      |     -     |   3.37   \n",
            "   1    |   300   |   0.379974   |     -      |     -     |   3.38   \n",
            "   1    |   320   |   0.364257   |     -      |     -     |   3.36   \n",
            "   1    |   340   |   0.348894   |     -      |     -     |   3.38   \n",
            "   1    |   360   |   0.347180   |     -      |     -     |   3.39   \n",
            "   1    |   380   |   0.388491   |     -      |     -     |   3.39   \n",
            "   1    |   400   |   0.342393   |     -      |     -     |   3.40   \n",
            "   1    |   420   |   0.358995   |     -      |     -     |   3.41   \n",
            "   1    |   440   |   0.402445   |     -      |     -     |   3.42   \n",
            "   1    |   460   |   0.404434   |     -      |     -     |   3.43   \n",
            "   1    |   480   |   0.364283   |     -      |     -     |   3.43   \n",
            "   1    |   500   |   0.388740   |     -      |     -     |   3.42   \n",
            "   1    |   520   |   0.374141   |     -      |     -     |   3.42   \n",
            "   1    |   540   |   0.312768   |     -      |     -     |   3.42   \n",
            "   1    |   560   |   0.383036   |     -      |     -     |   3.41   \n",
            "   1    |   580   |   0.382454   |     -      |     -     |   3.41   \n",
            "   1    |   600   |   0.369070   |     -      |     -     |   3.40   \n",
            "   1    |   620   |   0.424830   |     -      |     -     |   3.40   \n",
            "   1    |   640   |   0.370595   |     -      |     -     |   3.41   \n",
            "   1    |   660   |   0.346154   |     -      |     -     |   3.39   \n",
            "   1    |   680   |   0.423202   |     -      |     -     |   3.39   \n",
            "   1    |   700   |   0.339342   |     -      |     -     |   3.38   \n",
            "   1    |   720   |   0.348527   |     -      |     -     |   3.38   \n",
            "   1    |   740   |   0.324889   |     -      |     -     |   3.37   \n",
            "   1    |   760   |   0.344314   |     -      |     -     |   3.38   \n",
            "   1    |   780   |   0.396074   |     -      |     -     |   3.37   \n",
            "   1    |   800   |   0.352884   |     -      |     -     |   3.38   \n",
            "   1    |   820   |   0.324073   |     -      |     -     |   3.38   \n",
            "   1    |   840   |   0.294407   |     -      |     -     |   3.38   \n",
            "   1    |   860   |   0.384737   |     -      |     -     |   3.38   \n",
            "   1    |   880   |   0.368950   |     -      |     -     |   3.38   \n",
            "   1    |   900   |   0.278942   |     -      |     -     |   3.38   \n",
            "   1    |   920   |   0.342626   |     -      |     -     |   3.39   \n",
            "   1    |   940   |   0.348984   |     -      |     -     |   3.39   \n",
            "   1    |   960   |   0.298341   |     -      |     -     |   3.38   \n",
            "   1    |   980   |   0.347327   |     -      |     -     |   3.40   \n",
            "   1    |   999   |   0.365016   |     -      |     -     |   3.23   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.394739   |  0.345396  |   83.60   |  184.44  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.228468   |     -      |     -     |   3.57   \n",
            "   2    |   40    |   0.223238   |     -      |     -     |   3.40   \n",
            "   2    |   60    |   0.312358   |     -      |     -     |   3.39   \n",
            "   2    |   80    |   0.214807   |     -      |     -     |   3.39   \n",
            "   2    |   100   |   0.278422   |     -      |     -     |   3.39   \n",
            "   2    |   120   |   0.242769   |     -      |     -     |   3.39   \n",
            "   2    |   140   |   0.242548   |     -      |     -     |   3.39   \n",
            "   2    |   160   |   0.187365   |     -      |     -     |   3.39   \n",
            "   2    |   180   |   0.226273   |     -      |     -     |   3.39   \n",
            "   2    |   200   |   0.272010   |     -      |     -     |   3.39   \n",
            "   2    |   220   |   0.239807   |     -      |     -     |   3.39   \n",
            "   2    |   240   |   0.281466   |     -      |     -     |   3.38   \n",
            "   2    |   260   |   0.217643   |     -      |     -     |   3.39   \n",
            "   2    |   280   |   0.193463   |     -      |     -     |   3.38   \n",
            "   2    |   300   |   0.294856   |     -      |     -     |   3.38   \n",
            "   2    |   320   |   0.219398   |     -      |     -     |   3.38   \n",
            "   2    |   340   |   0.301142   |     -      |     -     |   3.39   \n",
            "   2    |   360   |   0.242607   |     -      |     -     |   3.39   \n",
            "   2    |   380   |   0.222404   |     -      |     -     |   3.38   \n",
            "   2    |   400   |   0.230806   |     -      |     -     |   3.39   \n",
            "   2    |   420   |   0.221800   |     -      |     -     |   3.39   \n",
            "   2    |   440   |   0.231896   |     -      |     -     |   3.38   \n",
            "   2    |   460   |   0.170409   |     -      |     -     |   3.39   \n",
            "   2    |   480   |   0.231325   |     -      |     -     |   3.39   \n",
            "   2    |   500   |   0.259884   |     -      |     -     |   3.38   \n",
            "   2    |   520   |   0.196517   |     -      |     -     |   3.40   \n",
            "   2    |   540   |   0.191994   |     -      |     -     |   3.39   \n",
            "   2    |   560   |   0.215339   |     -      |     -     |   3.39   \n",
            "   2    |   580   |   0.230855   |     -      |     -     |   3.39   \n",
            "   2    |   600   |   0.252782   |     -      |     -     |   3.39   \n",
            "   2    |   620   |   0.250890   |     -      |     -     |   3.40   \n",
            "   2    |   640   |   0.205501   |     -      |     -     |   3.42   \n",
            "   2    |   660   |   0.240631   |     -      |     -     |   3.40   \n",
            "   2    |   680   |   0.236156   |     -      |     -     |   3.40   \n",
            "   2    |   700   |   0.211282   |     -      |     -     |   3.39   \n",
            "   2    |   720   |   0.197349   |     -      |     -     |   3.39   \n",
            "   2    |   740   |   0.196966   |     -      |     -     |   3.39   \n",
            "   2    |   760   |   0.308359   |     -      |     -     |   3.39   \n",
            "   2    |   780   |   0.258060   |     -      |     -     |   3.39   \n",
            "   2    |   800   |   0.219449   |     -      |     -     |   3.39   \n",
            "   2    |   820   |   0.243453   |     -      |     -     |   3.39   \n",
            "   2    |   840   |   0.255973   |     -      |     -     |   3.39   \n",
            "   2    |   860   |   0.298646   |     -      |     -     |   3.40   \n",
            "   2    |   880   |   0.182200   |     -      |     -     |   3.39   \n",
            "   2    |   900   |   0.235646   |     -      |     -     |   3.39   \n",
            "   2    |   920   |   0.199329   |     -      |     -     |   3.39   \n",
            "   2    |   940   |   0.236748   |     -      |     -     |   3.39   \n",
            "   2    |   960   |   0.253561   |     -      |     -     |   3.39   \n",
            "   2    |   980   |   0.264578   |     -      |     -     |   3.39   \n",
            "   2    |   999   |   0.250289   |     -      |     -     |   3.23   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.236372   |  0.348918  |   85.10   |  184.26  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.158583   |     -      |     -     |   3.56   \n",
            "   3    |   40    |   0.099494   |     -      |     -     |   3.39   \n",
            "   3    |   60    |   0.088846   |     -      |     -     |   3.39   \n",
            "   3    |   80    |   0.062183   |     -      |     -     |   3.39   \n",
            "   3    |   100   |   0.198480   |     -      |     -     |   3.39   \n",
            "   3    |   120   |   0.076145   |     -      |     -     |   3.38   \n",
            "   3    |   140   |   0.095483   |     -      |     -     |   3.39   \n",
            "   3    |   160   |   0.116168   |     -      |     -     |   3.38   \n",
            "   3    |   180   |   0.176793   |     -      |     -     |   3.39   \n",
            "   3    |   200   |   0.076533   |     -      |     -     |   3.39   \n",
            "   3    |   220   |   0.122979   |     -      |     -     |   3.39   \n",
            "   3    |   240   |   0.168855   |     -      |     -     |   3.38   \n",
            "   3    |   260   |   0.078964   |     -      |     -     |   3.39   \n",
            "   3    |   280   |   0.089840   |     -      |     -     |   3.40   \n",
            "   3    |   300   |   0.129301   |     -      |     -     |   3.39   \n",
            "   3    |   320   |   0.141212   |     -      |     -     |   3.38   \n",
            "   3    |   340   |   0.165003   |     -      |     -     |   3.39   \n",
            "   3    |   360   |   0.089704   |     -      |     -     |   3.39   \n",
            "   3    |   380   |   0.167054   |     -      |     -     |   3.39   \n",
            "   3    |   400   |   0.169636   |     -      |     -     |   3.39   \n",
            "   3    |   420   |   0.091151   |     -      |     -     |   3.39   \n",
            "   3    |   440   |   0.134647   |     -      |     -     |   3.39   \n",
            "   3    |   460   |   0.119088   |     -      |     -     |   3.39   \n",
            "   3    |   480   |   0.158489   |     -      |     -     |   3.39   \n",
            "   3    |   500   |   0.086888   |     -      |     -     |   3.39   \n",
            "   3    |   520   |   0.102294   |     -      |     -     |   3.39   \n",
            "   3    |   540   |   0.131302   |     -      |     -     |   3.39   \n",
            "   3    |   560   |   0.184923   |     -      |     -     |   3.39   \n",
            "   3    |   580   |   0.186990   |     -      |     -     |   3.39   \n",
            "   3    |   600   |   0.142994   |     -      |     -     |   3.39   \n",
            "   3    |   620   |   0.097168   |     -      |     -     |   3.39   \n",
            "   3    |   640   |   0.180044   |     -      |     -     |   3.40   \n",
            "   3    |   660   |   0.162043   |     -      |     -     |   3.38   \n",
            "   3    |   680   |   0.230413   |     -      |     -     |   3.39   \n",
            "   3    |   700   |   0.160984   |     -      |     -     |   3.39   \n",
            "   3    |   720   |   0.115771   |     -      |     -     |   3.39   \n",
            "   3    |   740   |   0.157337   |     -      |     -     |   3.39   \n",
            "   3    |   760   |   0.134252   |     -      |     -     |   3.39   \n",
            "   3    |   780   |   0.082005   |     -      |     -     |   3.38   \n",
            "   3    |   800   |   0.106901   |     -      |     -     |   3.39   \n",
            "   3    |   820   |   0.149550   |     -      |     -     |   3.39   \n",
            "   3    |   840   |   0.155483   |     -      |     -     |   3.39   \n",
            "   3    |   860   |   0.169106   |     -      |     -     |   3.39   \n",
            "   3    |   880   |   0.043923   |     -      |     -     |   3.39   \n",
            "   3    |   900   |   0.123065   |     -      |     -     |   3.39   \n",
            "   3    |   920   |   0.122180   |     -      |     -     |   3.39   \n",
            "   3    |   940   |   0.129326   |     -      |     -     |   3.39   \n",
            "   3    |   960   |   0.155748   |     -      |     -     |   3.40   \n",
            "   3    |   980   |   0.106567   |     -      |     -     |   3.39   \n",
            "   3    |   999   |   0.114306   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.130168   |  0.627246  |   83.92   |  184.26  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.099441   |     -      |     -     |   3.56   \n",
            "   4    |   40    |   0.069200   |     -      |     -     |   3.39   \n",
            "   4    |   60    |   0.061053   |     -      |     -     |   3.39   \n",
            "   4    |   80    |   0.047366   |     -      |     -     |   3.39   \n",
            "   4    |   100   |   0.062357   |     -      |     -     |   3.38   \n",
            "   4    |   120   |   0.087292   |     -      |     -     |   3.38   \n",
            "   4    |   140   |   0.071810   |     -      |     -     |   3.38   \n",
            "   4    |   160   |   0.039003   |     -      |     -     |   3.38   \n",
            "   4    |   180   |   0.086103   |     -      |     -     |   3.39   \n",
            "   4    |   200   |   0.137685   |     -      |     -     |   3.39   \n",
            "   4    |   220   |   0.047175   |     -      |     -     |   3.39   \n",
            "   4    |   240   |   0.051413   |     -      |     -     |   3.38   \n",
            "   4    |   260   |   0.106736   |     -      |     -     |   3.39   \n",
            "   4    |   280   |   0.098343   |     -      |     -     |   3.39   \n",
            "   4    |   300   |   0.074533   |     -      |     -     |   3.39   \n",
            "   4    |   320   |   0.076064   |     -      |     -     |   3.39   \n",
            "   4    |   340   |   0.056314   |     -      |     -     |   3.38   \n",
            "   4    |   360   |   0.124807   |     -      |     -     |   3.39   \n",
            "   4    |   380   |   0.113198   |     -      |     -     |   3.39   \n",
            "   4    |   400   |   0.111356   |     -      |     -     |   3.39   \n",
            "   4    |   420   |   0.056274   |     -      |     -     |   3.39   \n",
            "   4    |   440   |   0.069519   |     -      |     -     |   3.39   \n",
            "   4    |   460   |   0.081317   |     -      |     -     |   3.39   \n",
            "   4    |   480   |   0.086779   |     -      |     -     |   3.40   \n",
            "   4    |   500   |   0.089888   |     -      |     -     |   3.39   \n",
            "   4    |   520   |   0.121640   |     -      |     -     |   3.39   \n",
            "   4    |   540   |   0.065600   |     -      |     -     |   3.39   \n",
            "   4    |   560   |   0.046457   |     -      |     -     |   3.39   \n",
            "   4    |   580   |   0.084717   |     -      |     -     |   3.39   \n",
            "   4    |   600   |   0.058334   |     -      |     -     |   3.39   \n",
            "   4    |   620   |   0.058611   |     -      |     -     |   3.40   \n",
            "   4    |   640   |   0.054045   |     -      |     -     |   3.40   \n",
            "   4    |   660   |   0.105252   |     -      |     -     |   3.39   \n",
            "   4    |   680   |   0.073333   |     -      |     -     |   3.39   \n",
            "   4    |   700   |   0.145474   |     -      |     -     |   3.39   \n",
            "   4    |   720   |   0.047714   |     -      |     -     |   3.39   \n",
            "   4    |   740   |   0.127511   |     -      |     -     |   3.39   \n",
            "   4    |   760   |   0.104548   |     -      |     -     |   3.39   \n",
            "   4    |   780   |   0.121372   |     -      |     -     |   3.39   \n",
            "   4    |   800   |   0.080511   |     -      |     -     |   3.39   \n",
            "   4    |   820   |   0.108287   |     -      |     -     |   3.39   \n",
            "   4    |   840   |   0.052965   |     -      |     -     |   3.39   \n",
            "   4    |   860   |   0.072656   |     -      |     -     |   3.39   \n",
            "   4    |   880   |   0.109557   |     -      |     -     |   3.39   \n",
            "   4    |   900   |   0.051259   |     -      |     -     |   3.39   \n",
            "   4    |   920   |   0.024815   |     -      |     -     |   3.38   \n",
            "   4    |   940   |   0.107859   |     -      |     -     |   3.39   \n",
            "   4    |   960   |   0.051196   |     -      |     -     |   3.39   \n",
            "   4    |   980   |   0.110587   |     -      |     -     |   3.39   \n",
            "   4    |   999   |   0.105621   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.081893   |  0.815973  |   83.25   |  184.17  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   5    |   20    |   0.082853   |     -      |     -     |   3.56   \n",
            "   5    |   40    |   0.019303   |     -      |     -     |   3.39   \n",
            "   5    |   60    |   0.027023   |     -      |     -     |   3.39   \n",
            "   5    |   80    |   0.023607   |     -      |     -     |   3.39   \n",
            "   5    |   100   |   0.060403   |     -      |     -     |   3.39   \n",
            "   5    |   120   |   0.048032   |     -      |     -     |   3.39   \n",
            "   5    |   140   |   0.042175   |     -      |     -     |   3.39   \n",
            "   5    |   160   |   0.010302   |     -      |     -     |   3.39   \n",
            "   5    |   180   |   0.018776   |     -      |     -     |   3.39   \n",
            "   5    |   200   |   0.018675   |     -      |     -     |   3.39   \n",
            "   5    |   220   |   0.061125   |     -      |     -     |   3.39   \n",
            "   5    |   240   |   0.054695   |     -      |     -     |   3.39   \n",
            "   5    |   260   |   0.038696   |     -      |     -     |   3.39   \n",
            "   5    |   280   |   0.053783   |     -      |     -     |   3.40   \n",
            "   5    |   300   |   0.034803   |     -      |     -     |   3.39   \n",
            "   5    |   320   |   0.041475   |     -      |     -     |   3.39   \n",
            "   5    |   340   |   0.080388   |     -      |     -     |   3.39   \n",
            "   5    |   360   |   0.086118   |     -      |     -     |   3.39   \n",
            "   5    |   380   |   0.049095   |     -      |     -     |   3.39   \n",
            "   5    |   400   |   0.030345   |     -      |     -     |   3.39   \n",
            "   5    |   420   |   0.022573   |     -      |     -     |   3.39   \n",
            "   5    |   440   |   0.066069   |     -      |     -     |   3.39   \n",
            "   5    |   460   |   0.045304   |     -      |     -     |   3.39   \n",
            "   5    |   480   |   0.049292   |     -      |     -     |   3.39   \n",
            "   5    |   500   |   0.042968   |     -      |     -     |   3.39   \n",
            "   5    |   520   |   0.019856   |     -      |     -     |   3.39   \n",
            "   5    |   540   |   0.038344   |     -      |     -     |   3.39   \n",
            "   5    |   560   |   0.044303   |     -      |     -     |   3.40   \n",
            "   5    |   580   |   0.031161   |     -      |     -     |   3.39   \n",
            "   5    |   600   |   0.115189   |     -      |     -     |   3.39   \n",
            "   5    |   620   |   0.019924   |     -      |     -     |   3.40   \n",
            "   5    |   640   |   0.064641   |     -      |     -     |   3.41   \n",
            "   5    |   660   |   0.034084   |     -      |     -     |   3.39   \n",
            "   5    |   680   |   0.088690   |     -      |     -     |   3.39   \n",
            "   5    |   700   |   0.029944   |     -      |     -     |   3.39   \n",
            "   5    |   720   |   0.027644   |     -      |     -     |   3.39   \n",
            "   5    |   740   |   0.053524   |     -      |     -     |   3.39   \n",
            "   5    |   760   |   0.051501   |     -      |     -     |   3.39   \n",
            "   5    |   780   |   0.079385   |     -      |     -     |   3.39   \n",
            "   5    |   800   |   0.074103   |     -      |     -     |   3.40   \n",
            "   5    |   820   |   0.101046   |     -      |     -     |   3.39   \n",
            "   5    |   840   |   0.066359   |     -      |     -     |   3.39   \n",
            "   5    |   860   |   0.030574   |     -      |     -     |   3.40   \n",
            "   5    |   880   |   0.040825   |     -      |     -     |   3.40   \n",
            "   5    |   900   |   0.022591   |     -      |     -     |   3.39   \n",
            "   5    |   920   |   0.016556   |     -      |     -     |   3.39   \n",
            "   5    |   940   |   0.017691   |     -      |     -     |   3.39   \n",
            "   5    |   960   |   0.041326   |     -      |     -     |   3.39   \n",
            "   5    |   980   |   0.107760   |     -      |     -     |   3.39   \n",
            "   5    |   999   |   0.079214   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "   5    |    -    |   0.048086   |  0.981500  |   84.42   |  184.30  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   6    |   20    |   0.025468   |     -      |     -     |   3.57   \n",
            "   6    |   40    |   0.045269   |     -      |     -     |   3.39   \n",
            "   6    |   60    |   0.015206   |     -      |     -     |   3.39   \n",
            "   6    |   80    |   0.033228   |     -      |     -     |   3.39   \n",
            "   6    |   100   |   0.015831   |     -      |     -     |   3.39   \n",
            "   6    |   120   |   0.018499   |     -      |     -     |   3.39   \n",
            "   6    |   140   |   0.022882   |     -      |     -     |   3.38   \n",
            "   6    |   160   |   0.053608   |     -      |     -     |   3.39   \n",
            "   6    |   180   |   0.030257   |     -      |     -     |   3.39   \n",
            "   6    |   200   |   0.027498   |     -      |     -     |   3.38   \n",
            "   6    |   220   |   0.003460   |     -      |     -     |   3.39   \n",
            "   6    |   240   |   0.056147   |     -      |     -     |   3.39   \n",
            "   6    |   260   |   0.013490   |     -      |     -     |   3.39   \n",
            "   6    |   280   |   0.006662   |     -      |     -     |   3.40   \n",
            "   6    |   300   |   0.028720   |     -      |     -     |   3.38   \n",
            "   6    |   320   |   0.001819   |     -      |     -     |   3.39   \n",
            "   6    |   340   |   0.041640   |     -      |     -     |   3.39   \n",
            "   6    |   360   |   0.048567   |     -      |     -     |   3.39   \n",
            "   6    |   380   |   0.078932   |     -      |     -     |   3.39   \n",
            "   6    |   400   |   0.018063   |     -      |     -     |   3.38   \n",
            "   6    |   420   |   0.003810   |     -      |     -     |   3.39   \n",
            "   6    |   440   |   0.044029   |     -      |     -     |   3.39   \n",
            "   6    |   460   |   0.052353   |     -      |     -     |   3.39   \n",
            "   6    |   480   |   0.000552   |     -      |     -     |   3.39   \n",
            "   6    |   500   |   0.018746   |     -      |     -     |   3.40   \n",
            "   6    |   520   |   0.033992   |     -      |     -     |   3.40   \n",
            "   6    |   540   |   0.014549   |     -      |     -     |   3.38   \n",
            "   6    |   560   |   0.046527   |     -      |     -     |   3.40   \n",
            "   6    |   580   |   0.051451   |     -      |     -     |   3.39   \n",
            "   6    |   600   |   0.059329   |     -      |     -     |   3.39   \n",
            "   6    |   620   |   0.054858   |     -      |     -     |   3.39   \n",
            "   6    |   640   |   0.032877   |     -      |     -     |   3.39   \n",
            "   6    |   660   |   0.076258   |     -      |     -     |   3.39   \n",
            "   6    |   680   |   0.079612   |     -      |     -     |   3.39   \n",
            "   6    |   700   |   0.068329   |     -      |     -     |   3.39   \n",
            "   6    |   720   |   0.031530   |     -      |     -     |   3.38   \n",
            "   6    |   740   |   0.024126   |     -      |     -     |   3.39   \n",
            "   6    |   760   |   0.021751   |     -      |     -     |   3.39   \n",
            "   6    |   780   |   0.052513   |     -      |     -     |   3.39   \n",
            "   6    |   800   |   0.002192   |     -      |     -     |   3.39   \n",
            "   6    |   820   |   0.027263   |     -      |     -     |   3.39   \n",
            "   6    |   840   |   0.013569   |     -      |     -     |   3.39   \n",
            "   6    |   860   |   0.090840   |     -      |     -     |   3.39   \n",
            "   6    |   880   |   0.004769   |     -      |     -     |   3.39   \n",
            "   6    |   900   |   0.077403   |     -      |     -     |   3.39   \n",
            "   6    |   920   |   0.013206   |     -      |     -     |   3.38   \n",
            "   6    |   940   |   0.025224   |     -      |     -     |   3.39   \n",
            "   6    |   960   |   0.044161   |     -      |     -     |   3.39   \n",
            "   6    |   980   |   0.028727   |     -      |     -     |   3.39   \n",
            "   6    |   999   |   0.074544   |     -      |     -     |   3.21   \n",
            "----------------------------------------------------------------------\n",
            "   6    |    -    |   0.035038   |  1.025167  |   84.12   |  184.19  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   7    |   20    |   0.020161   |     -      |     -     |   3.56   \n",
            "   7    |   40    |   0.000851   |     -      |     -     |   3.39   \n",
            "   7    |   60    |   0.001749   |     -      |     -     |   3.39   \n",
            "   7    |   80    |   0.007018   |     -      |     -     |   3.39   \n",
            "   7    |   100   |   0.047412   |     -      |     -     |   3.39   \n",
            "   7    |   120   |   0.040324   |     -      |     -     |   3.39   \n",
            "   7    |   140   |   0.000951   |     -      |     -     |   3.39   \n",
            "   7    |   160   |   0.011309   |     -      |     -     |   3.39   \n",
            "   7    |   180   |   0.019772   |     -      |     -     |   3.39   \n",
            "   7    |   200   |   0.017586   |     -      |     -     |   3.39   \n",
            "   7    |   220   |   0.028171   |     -      |     -     |   3.39   \n",
            "   7    |   240   |   0.046265   |     -      |     -     |   3.39   \n",
            "   7    |   260   |   0.048314   |     -      |     -     |   3.40   \n",
            "   7    |   280   |   0.057282   |     -      |     -     |   3.39   \n",
            "   7    |   300   |   0.052010   |     -      |     -     |   3.39   \n",
            "   7    |   320   |   0.011093   |     -      |     -     |   3.39   \n",
            "   7    |   340   |   0.018626   |     -      |     -     |   3.38   \n",
            "   7    |   360   |   0.002801   |     -      |     -     |   3.39   \n",
            "   7    |   380   |   0.066953   |     -      |     -     |   3.39   \n",
            "   7    |   400   |   0.014291   |     -      |     -     |   3.39   \n",
            "   7    |   420   |   0.012901   |     -      |     -     |   3.39   \n",
            "   7    |   440   |   0.034639   |     -      |     -     |   3.39   \n",
            "   7    |   460   |   0.049393   |     -      |     -     |   3.39   \n",
            "   7    |   480   |   0.010512   |     -      |     -     |   3.39   \n",
            "   7    |   500   |   0.000719   |     -      |     -     |   3.40   \n",
            "   7    |   520   |   0.008329   |     -      |     -     |   3.39   \n",
            "   7    |   540   |   0.026575   |     -      |     -     |   3.39   \n",
            "   7    |   560   |   0.031294   |     -      |     -     |   3.39   \n",
            "   7    |   580   |   0.032199   |     -      |     -     |   3.39   \n",
            "   7    |   600   |   0.006983   |     -      |     -     |   3.39   \n",
            "   7    |   620   |   0.034296   |     -      |     -     |   3.39   \n",
            "   7    |   640   |   0.051024   |     -      |     -     |   3.40   \n",
            "   7    |   660   |   0.028932   |     -      |     -     |   3.39   \n",
            "   7    |   680   |   0.043848   |     -      |     -     |   3.39   \n",
            "   7    |   700   |   0.056271   |     -      |     -     |   3.39   \n",
            "   7    |   720   |   0.083022   |     -      |     -     |   3.39   \n",
            "   7    |   740   |   0.050193   |     -      |     -     |   3.39   \n",
            "   7    |   760   |   0.048843   |     -      |     -     |   3.39   \n",
            "   7    |   780   |   0.035366   |     -      |     -     |   3.40   \n",
            "   7    |   800   |   0.001937   |     -      |     -     |   3.39   \n",
            "   7    |   820   |   0.004410   |     -      |     -     |   3.39   \n",
            "   7    |   840   |   0.023475   |     -      |     -     |   3.39   \n",
            "   7    |   860   |   0.011160   |     -      |     -     |   3.39   \n",
            "   7    |   880   |   0.039139   |     -      |     -     |   3.39   \n",
            "   7    |   900   |   0.027128   |     -      |     -     |   3.39   \n",
            "   7    |   920   |   0.042750   |     -      |     -     |   3.39   \n",
            "   7    |   940   |   0.027698   |     -      |     -     |   3.39   \n",
            "   7    |   960   |   0.046186   |     -      |     -     |   3.39   \n",
            "   7    |   980   |   0.010854   |     -      |     -     |   3.40   \n",
            "   7    |   999   |   0.032490   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "   7    |    -    |   0.028498   |  0.981009  |   84.80   |  184.21  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   8    |   20    |   0.010491   |     -      |     -     |   3.56   \n",
            "   8    |   40    |   0.001068   |     -      |     -     |   3.38   \n",
            "   8    |   60    |   0.000222   |     -      |     -     |   3.39   \n",
            "   8    |   80    |   0.000236   |     -      |     -     |   3.38   \n",
            "   8    |   100   |   0.006884   |     -      |     -     |   3.39   \n",
            "   8    |   120   |   0.000442   |     -      |     -     |   3.38   \n",
            "   8    |   140   |   0.026250   |     -      |     -     |   3.39   \n",
            "   8    |   160   |   0.000251   |     -      |     -     |   3.38   \n",
            "   8    |   180   |   0.000213   |     -      |     -     |   3.39   \n",
            "   8    |   200   |   0.022144   |     -      |     -     |   3.38   \n",
            "   8    |   220   |   0.021049   |     -      |     -     |   3.39   \n",
            "   8    |   240   |   0.000155   |     -      |     -     |   3.39   \n",
            "   8    |   260   |   0.027360   |     -      |     -     |   3.39   \n",
            "   8    |   280   |   0.000202   |     -      |     -     |   3.39   \n",
            "   8    |   300   |   0.000325   |     -      |     -     |   3.39   \n",
            "   8    |   320   |   0.021655   |     -      |     -     |   3.39   \n",
            "   8    |   340   |   0.000156   |     -      |     -     |   3.39   \n",
            "   8    |   360   |   0.000434   |     -      |     -     |   3.39   \n",
            "   8    |   380   |   0.000153   |     -      |     -     |   3.39   \n",
            "   8    |   400   |   0.053918   |     -      |     -     |   3.39   \n",
            "   8    |   420   |   0.048350   |     -      |     -     |   3.39   \n",
            "   8    |   440   |   0.010729   |     -      |     -     |   3.39   \n",
            "   8    |   460   |   0.030382   |     -      |     -     |   3.39   \n",
            "   8    |   480   |   0.067808   |     -      |     -     |   3.39   \n",
            "   8    |   500   |   0.033146   |     -      |     -     |   3.39   \n",
            "   8    |   520   |   0.018486   |     -      |     -     |   3.39   \n",
            "   8    |   540   |   0.024803   |     -      |     -     |   3.39   \n",
            "   8    |   560   |   0.032724   |     -      |     -     |   3.38   \n",
            "   8    |   580   |   0.015969   |     -      |     -     |   3.39   \n",
            "   8    |   600   |   0.034144   |     -      |     -     |   3.39   \n",
            "   8    |   620   |   0.034625   |     -      |     -     |   3.39   \n",
            "   8    |   640   |   0.021179   |     -      |     -     |   3.39   \n",
            "   8    |   660   |   0.000367   |     -      |     -     |   3.39   \n",
            "   8    |   680   |   0.001412   |     -      |     -     |   3.38   \n",
            "   8    |   700   |   0.033653   |     -      |     -     |   3.39   \n",
            "   8    |   720   |   0.039492   |     -      |     -     |   3.39   \n",
            "   8    |   740   |   0.052373   |     -      |     -     |   3.39   \n",
            "   8    |   760   |   0.084313   |     -      |     -     |   3.39   \n",
            "   8    |   780   |   0.008526   |     -      |     -     |   3.38   \n",
            "   8    |   800   |   0.014755   |     -      |     -     |   3.39   \n",
            "   8    |   820   |   0.005742   |     -      |     -     |   3.39   \n",
            "   8    |   840   |   0.075575   |     -      |     -     |   3.39   \n",
            "   8    |   860   |   0.057509   |     -      |     -     |   3.39   \n",
            "   8    |   880   |   0.000565   |     -      |     -     |   3.39   \n",
            "   8    |   900   |   0.032526   |     -      |     -     |   3.39   \n",
            "   8    |   920   |   0.037166   |     -      |     -     |   3.39   \n",
            "   8    |   940   |   0.018641   |     -      |     -     |   3.39   \n",
            "   8    |   960   |   0.035881   |     -      |     -     |   3.39   \n",
            "   8    |   980   |   0.028749   |     -      |     -     |   3.39   \n",
            "   8    |   999   |   0.000531   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "   8    |    -    |   0.021884   |  1.114078  |   84.70   |  184.14  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   9    |   20    |   0.010141   |     -      |     -     |   3.57   \n",
            "   9    |   40    |   0.024347   |     -      |     -     |   3.39   \n",
            "   9    |   60    |   0.004179   |     -      |     -     |   3.38   \n",
            "   9    |   80    |   0.000248   |     -      |     -     |   3.39   \n",
            "   9    |   100   |   0.009486   |     -      |     -     |   3.39   \n",
            "   9    |   120   |   0.006042   |     -      |     -     |   3.39   \n",
            "   9    |   140   |   0.005359   |     -      |     -     |   3.38   \n",
            "   9    |   160   |   0.007710   |     -      |     -     |   3.38   \n",
            "   9    |   180   |   0.001005   |     -      |     -     |   3.38   \n",
            "   9    |   200   |   0.021383   |     -      |     -     |   3.39   \n",
            "   9    |   220   |   0.000217   |     -      |     -     |   3.39   \n",
            "   9    |   240   |   0.026338   |     -      |     -     |   3.39   \n",
            "   9    |   260   |   0.000194   |     -      |     -     |   3.39   \n",
            "   9    |   280   |   0.027948   |     -      |     -     |   3.39   \n",
            "   9    |   300   |   0.005884   |     -      |     -     |   3.39   \n",
            "   9    |   320   |   0.015555   |     -      |     -     |   3.39   \n",
            "   9    |   340   |   0.026068   |     -      |     -     |   3.39   \n",
            "   9    |   360   |   0.024854   |     -      |     -     |   3.39   \n",
            "   9    |   380   |   0.016823   |     -      |     -     |   3.39   \n",
            "   9    |   400   |   0.001334   |     -      |     -     |   3.39   \n",
            "   9    |   420   |   0.000157   |     -      |     -     |   3.40   \n",
            "   9    |   440   |   0.005291   |     -      |     -     |   3.40   \n",
            "   9    |   460   |   0.024434   |     -      |     -     |   3.39   \n",
            "   9    |   480   |   0.013507   |     -      |     -     |   3.40   \n",
            "   9    |   500   |   0.105034   |     -      |     -     |   3.39   \n",
            "   9    |   520   |   0.021883   |     -      |     -     |   3.39   \n",
            "   9    |   540   |   0.019495   |     -      |     -     |   3.39   \n",
            "   9    |   560   |   0.030711   |     -      |     -     |   3.39   \n",
            "   9    |   580   |   0.034864   |     -      |     -     |   3.39   \n",
            "   9    |   600   |   0.067388   |     -      |     -     |   3.39   \n",
            "   9    |   620   |   0.001577   |     -      |     -     |   3.39   \n",
            "   9    |   640   |   0.027322   |     -      |     -     |   3.39   \n",
            "   9    |   660   |   0.020408   |     -      |     -     |   3.41   \n",
            "   9    |   680   |   0.009970   |     -      |     -     |   3.39   \n",
            "   9    |   700   |   0.041645   |     -      |     -     |   3.39   \n",
            "   9    |   720   |   0.047234   |     -      |     -     |   3.39   \n",
            "   9    |   740   |   0.048378   |     -      |     -     |   3.39   \n",
            "   9    |   760   |   0.043629   |     -      |     -     |   3.39   \n",
            "   9    |   780   |   0.028233   |     -      |     -     |   3.39   \n",
            "   9    |   800   |   0.018804   |     -      |     -     |   3.39   \n",
            "   9    |   820   |   0.000519   |     -      |     -     |   3.38   \n",
            "   9    |   840   |   0.024436   |     -      |     -     |   3.38   \n",
            "   9    |   860   |   0.043432   |     -      |     -     |   3.39   \n",
            "   9    |   880   |   0.015061   |     -      |     -     |   3.39   \n",
            "   9    |   900   |   0.007561   |     -      |     -     |   3.39   \n",
            "   9    |   920   |   0.000845   |     -      |     -     |   3.39   \n",
            "   9    |   940   |   0.000180   |     -      |     -     |   3.39   \n",
            "   9    |   960   |   0.017582   |     -      |     -     |   3.38   \n",
            "   9    |   980   |   0.025079   |     -      |     -     |   3.39   \n",
            "   9    |   999   |   0.023225   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "   9    |    -    |   0.020047   |  1.146208  |   84.62   |  184.20  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  10    |   20    |   0.000800   |     -      |     -     |   3.56   \n",
            "  10    |   40    |   0.000235   |     -      |     -     |   3.39   \n",
            "  10    |   60    |   0.000971   |     -      |     -     |   3.39   \n",
            "  10    |   80    |   0.049930   |     -      |     -     |   3.40   \n",
            "  10    |   100   |   0.005276   |     -      |     -     |   3.39   \n",
            "  10    |   120   |   0.033716   |     -      |     -     |   3.39   \n",
            "  10    |   140   |   0.020609   |     -      |     -     |   3.38   \n",
            "  10    |   160   |   0.074954   |     -      |     -     |   3.39   \n",
            "  10    |   180   |   0.021008   |     -      |     -     |   3.39   \n",
            "  10    |   200   |   0.000424   |     -      |     -     |   3.39   \n",
            "  10    |   220   |   0.004615   |     -      |     -     |   3.39   \n",
            "  10    |   240   |   0.000532   |     -      |     -     |   3.39   \n",
            "  10    |   260   |   0.000227   |     -      |     -     |   3.39   \n",
            "  10    |   280   |   0.041273   |     -      |     -     |   3.39   \n",
            "  10    |   300   |   0.023892   |     -      |     -     |   3.40   \n",
            "  10    |   320   |   0.034663   |     -      |     -     |   3.39   \n",
            "  10    |   340   |   0.014351   |     -      |     -     |   3.39   \n",
            "  10    |   360   |   0.000387   |     -      |     -     |   3.38   \n",
            "  10    |   380   |   0.012403   |     -      |     -     |   3.39   \n",
            "  10    |   400   |   0.012417   |     -      |     -     |   3.39   \n",
            "  10    |   420   |   0.000878   |     -      |     -     |   3.39   \n",
            "  10    |   440   |   0.048576   |     -      |     -     |   3.39   \n",
            "  10    |   460   |   0.000570   |     -      |     -     |   3.39   \n",
            "  10    |   480   |   0.000309   |     -      |     -     |   3.39   \n",
            "  10    |   500   |   0.041914   |     -      |     -     |   3.39   \n",
            "  10    |   520   |   0.102337   |     -      |     -     |   3.39   \n",
            "  10    |   540   |   0.039017   |     -      |     -     |   3.39   \n",
            "  10    |   560   |   0.000252   |     -      |     -     |   3.39   \n",
            "  10    |   580   |   0.005547   |     -      |     -     |   3.39   \n",
            "  10    |   600   |   0.023833   |     -      |     -     |   3.39   \n",
            "  10    |   620   |   0.012550   |     -      |     -     |   3.39   \n",
            "  10    |   640   |   0.007358   |     -      |     -     |   3.39   \n",
            "  10    |   660   |   0.000241   |     -      |     -     |   3.39   \n",
            "  10    |   680   |   0.015109   |     -      |     -     |   3.39   \n",
            "  10    |   700   |   0.028391   |     -      |     -     |   3.39   \n",
            "  10    |   720   |   0.010593   |     -      |     -     |   3.38   \n",
            "  10    |   740   |   0.023921   |     -      |     -     |   3.39   \n",
            "  10    |   760   |   0.000356   |     -      |     -     |   3.39   \n",
            "  10    |   780   |   0.000366   |     -      |     -     |   3.40   \n",
            "  10    |   800   |   0.002148   |     -      |     -     |   3.39   \n",
            "  10    |   820   |   0.000105   |     -      |     -     |   3.39   \n",
            "  10    |   840   |   0.000746   |     -      |     -     |   3.39   \n",
            "  10    |   860   |   0.000152   |     -      |     -     |   3.39   \n",
            "  10    |   880   |   0.029604   |     -      |     -     |   3.39   \n",
            "  10    |   900   |   0.053380   |     -      |     -     |   3.38   \n",
            "  10    |   920   |   0.010164   |     -      |     -     |   3.39   \n",
            "  10    |   940   |   0.038709   |     -      |     -     |   3.39   \n",
            "  10    |   960   |   0.008633   |     -      |     -     |   3.39   \n",
            "  10    |   980   |   0.000220   |     -      |     -     |   3.39   \n",
            "  10    |   999   |   0.012727   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  10    |    -    |   0.017416   |  1.168323  |   84.60   |  184.21  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  11    |   20    |   0.004576   |     -      |     -     |   3.57   \n",
            "  11    |   40    |   0.002151   |     -      |     -     |   3.39   \n",
            "  11    |   60    |   0.024126   |     -      |     -     |   3.39   \n",
            "  11    |   80    |   0.012530   |     -      |     -     |   3.39   \n",
            "  11    |   100   |   0.014492   |     -      |     -     |   3.39   \n",
            "  11    |   120   |   0.038668   |     -      |     -     |   3.39   \n",
            "  11    |   140   |   0.000484   |     -      |     -     |   3.39   \n",
            "  11    |   160   |   0.021847   |     -      |     -     |   3.39   \n",
            "  11    |   180   |   0.000101   |     -      |     -     |   3.39   \n",
            "  11    |   200   |   0.031758   |     -      |     -     |   3.39   \n",
            "  11    |   220   |   0.049598   |     -      |     -     |   3.39   \n",
            "  11    |   240   |   0.005450   |     -      |     -     |   3.39   \n",
            "  11    |   260   |   0.011601   |     -      |     -     |   3.39   \n",
            "  11    |   280   |   0.002324   |     -      |     -     |   3.39   \n",
            "  11    |   300   |   0.029722   |     -      |     -     |   3.40   \n",
            "  11    |   320   |   0.039938   |     -      |     -     |   3.39   \n",
            "  11    |   340   |   0.094711   |     -      |     -     |   3.39   \n",
            "  11    |   360   |   0.000684   |     -      |     -     |   3.39   \n",
            "  11    |   380   |   0.006246   |     -      |     -     |   3.39   \n",
            "  11    |   400   |   0.018139   |     -      |     -     |   3.38   \n",
            "  11    |   420   |   0.000196   |     -      |     -     |   3.38   \n",
            "  11    |   440   |   0.000269   |     -      |     -     |   3.39   \n",
            "  11    |   460   |   0.024953   |     -      |     -     |   3.39   \n",
            "  11    |   480   |   0.037903   |     -      |     -     |   3.39   \n",
            "  11    |   500   |   0.023140   |     -      |     -     |   3.40   \n",
            "  11    |   520   |   0.001407   |     -      |     -     |   3.39   \n",
            "  11    |   540   |   0.001509   |     -      |     -     |   3.39   \n",
            "  11    |   560   |   0.009134   |     -      |     -     |   3.39   \n",
            "  11    |   580   |   0.008918   |     -      |     -     |   3.39   \n",
            "  11    |   600   |   0.000422   |     -      |     -     |   3.39   \n",
            "  11    |   620   |   0.015555   |     -      |     -     |   3.39   \n",
            "  11    |   640   |   0.000835   |     -      |     -     |   3.39   \n",
            "  11    |   660   |   0.017954   |     -      |     -     |   3.39   \n",
            "  11    |   680   |   0.019870   |     -      |     -     |   3.39   \n",
            "  11    |   700   |   0.037097   |     -      |     -     |   3.40   \n",
            "  11    |   720   |   0.000128   |     -      |     -     |   3.39   \n",
            "  11    |   740   |   0.017086   |     -      |     -     |   3.40   \n",
            "  11    |   760   |   0.000102   |     -      |     -     |   3.39   \n",
            "  11    |   780   |   0.003123   |     -      |     -     |   3.39   \n",
            "  11    |   800   |   0.020561   |     -      |     -     |   3.39   \n",
            "  11    |   820   |   0.036453   |     -      |     -     |   3.39   \n",
            "  11    |   840   |   0.009021   |     -      |     -     |   3.39   \n",
            "  11    |   860   |   0.000117   |     -      |     -     |   3.39   \n",
            "  11    |   880   |   0.024677   |     -      |     -     |   3.40   \n",
            "  11    |   900   |   0.030155   |     -      |     -     |   3.38   \n",
            "  11    |   920   |   0.034697   |     -      |     -     |   3.39   \n",
            "  11    |   940   |   0.000953   |     -      |     -     |   3.39   \n",
            "  11    |   960   |   0.016260   |     -      |     -     |   3.39   \n",
            "  11    |   980   |   0.000145   |     -      |     -     |   3.40   \n",
            "  11    |   999   |   0.039320   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  11    |    -    |   0.016787   |  1.128929  |   85.35   |  184.25  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  12    |   20    |   0.002812   |     -      |     -     |   3.56   \n",
            "  12    |   40    |   0.019730   |     -      |     -     |   3.39   \n",
            "  12    |   60    |   0.003767   |     -      |     -     |   3.39   \n",
            "  12    |   80    |   0.002129   |     -      |     -     |   3.38   \n",
            "  12    |   100   |   0.000093   |     -      |     -     |   3.38   \n",
            "  12    |   120   |   0.014578   |     -      |     -     |   3.39   \n",
            "  12    |   140   |   0.020268   |     -      |     -     |   3.39   \n",
            "  12    |   160   |   0.000150   |     -      |     -     |   3.38   \n",
            "  12    |   180   |   0.000182   |     -      |     -     |   3.39   \n",
            "  12    |   200   |   0.007499   |     -      |     -     |   3.39   \n",
            "  12    |   220   |   0.000082   |     -      |     -     |   3.39   \n",
            "  12    |   240   |   0.001637   |     -      |     -     |   3.39   \n",
            "  12    |   260   |   0.000076   |     -      |     -     |   3.38   \n",
            "  12    |   280   |   0.000126   |     -      |     -     |   3.39   \n",
            "  12    |   300   |   0.000082   |     -      |     -     |   3.39   \n",
            "  12    |   320   |   0.000231   |     -      |     -     |   3.40   \n",
            "  12    |   340   |   0.001663   |     -      |     -     |   3.39   \n",
            "  12    |   360   |   0.018028   |     -      |     -     |   3.39   \n",
            "  12    |   380   |   0.001646   |     -      |     -     |   3.39   \n",
            "  12    |   400   |   0.000078   |     -      |     -     |   3.39   \n",
            "  12    |   420   |   0.000044   |     -      |     -     |   3.39   \n",
            "  12    |   440   |   0.000061   |     -      |     -     |   3.39   \n",
            "  12    |   460   |   0.007526   |     -      |     -     |   3.39   \n",
            "  12    |   480   |   0.000090   |     -      |     -     |   3.39   \n",
            "  12    |   500   |   0.021047   |     -      |     -     |   3.39   \n",
            "  12    |   520   |   0.000071   |     -      |     -     |   3.39   \n",
            "  12    |   540   |   0.000817   |     -      |     -     |   3.39   \n",
            "  12    |   560   |   0.038979   |     -      |     -     |   3.39   \n",
            "  12    |   580   |   0.021408   |     -      |     -     |   3.39   \n",
            "  12    |   600   |   0.000180   |     -      |     -     |   3.39   \n",
            "  12    |   620   |   0.000091   |     -      |     -     |   3.39   \n",
            "  12    |   640   |   0.000092   |     -      |     -     |   3.39   \n",
            "  12    |   660   |   0.018344   |     -      |     -     |   3.42   \n",
            "  12    |   680   |   0.000239   |     -      |     -     |   3.39   \n",
            "  12    |   700   |   0.000254   |     -      |     -     |   3.39   \n",
            "  12    |   720   |   0.000080   |     -      |     -     |   3.39   \n",
            "  12    |   740   |   0.000086   |     -      |     -     |   3.39   \n",
            "  12    |   760   |   0.018026   |     -      |     -     |   3.38   \n",
            "  12    |   780   |   0.005132   |     -      |     -     |   3.39   \n",
            "  12    |   800   |   0.000140   |     -      |     -     |   3.39   \n",
            "  12    |   820   |   0.014617   |     -      |     -     |   3.39   \n",
            "  12    |   840   |   0.001566   |     -      |     -     |   3.39   \n",
            "  12    |   860   |   0.000076   |     -      |     -     |   3.40   \n",
            "  12    |   880   |   0.048893   |     -      |     -     |   3.39   \n",
            "  12    |   900   |   0.025905   |     -      |     -     |   3.39   \n",
            "  12    |   920   |   0.031153   |     -      |     -     |   3.39   \n",
            "  12    |   940   |   0.026237   |     -      |     -     |   3.40   \n",
            "  12    |   960   |   0.000989   |     -      |     -     |   3.39   \n",
            "  12    |   980   |   0.016718   |     -      |     -     |   3.40   \n",
            "  12    |   999   |   0.028189   |     -      |     -     |   3.23   \n",
            "----------------------------------------------------------------------\n",
            "  12    |    -    |   0.008413   |  1.084859  |   85.53   |  184.26  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  13    |   20    |   0.010241   |     -      |     -     |   3.55   \n",
            "  13    |   40    |   0.018994   |     -      |     -     |   3.39   \n",
            "  13    |   60    |   0.012706   |     -      |     -     |   3.39   \n",
            "  13    |   80    |   0.000096   |     -      |     -     |   3.38   \n",
            "  13    |   100   |   0.000113   |     -      |     -     |   3.39   \n",
            "  13    |   120   |   0.023971   |     -      |     -     |   3.39   \n",
            "  13    |   140   |   0.000100   |     -      |     -     |   3.38   \n",
            "  13    |   160   |   0.000083   |     -      |     -     |   3.38   \n",
            "  13    |   180   |   0.002324   |     -      |     -     |   3.39   \n",
            "  13    |   200   |   0.000278   |     -      |     -     |   3.39   \n",
            "  13    |   220   |   0.001676   |     -      |     -     |   3.38   \n",
            "  13    |   240   |   0.010299   |     -      |     -     |   3.39   \n",
            "  13    |   260   |   0.000047   |     -      |     -     |   3.39   \n",
            "  13    |   280   |   0.000052   |     -      |     -     |   3.39   \n",
            "  13    |   300   |   0.002592   |     -      |     -     |   3.41   \n",
            "  13    |   320   |   0.000052   |     -      |     -     |   3.39   \n",
            "  13    |   340   |   0.000041   |     -      |     -     |   3.39   \n",
            "  13    |   360   |   0.021121   |     -      |     -     |   3.39   \n",
            "  13    |   380   |   0.021982   |     -      |     -     |   3.39   \n",
            "  13    |   400   |   0.000062   |     -      |     -     |   3.40   \n",
            "  13    |   420   |   0.000054   |     -      |     -     |   3.39   \n",
            "  13    |   440   |   0.000081   |     -      |     -     |   3.39   \n",
            "  13    |   460   |   0.004449   |     -      |     -     |   3.39   \n",
            "  13    |   480   |   0.000049   |     -      |     -     |   3.39   \n",
            "  13    |   500   |   0.000118   |     -      |     -     |   3.39   \n",
            "  13    |   520   |   0.000075   |     -      |     -     |   3.39   \n",
            "  13    |   540   |   0.000136   |     -      |     -     |   3.39   \n",
            "  13    |   560   |   0.000049   |     -      |     -     |   3.39   \n",
            "  13    |   580   |   0.000568   |     -      |     -     |   3.39   \n",
            "  13    |   600   |   0.000174   |     -      |     -     |   3.39   \n",
            "  13    |   620   |   0.006039   |     -      |     -     |   3.39   \n",
            "  13    |   640   |   0.004659   |     -      |     -     |   3.40   \n",
            "  13    |   660   |   0.017101   |     -      |     -     |   3.39   \n",
            "  13    |   680   |   0.021064   |     -      |     -     |   3.40   \n",
            "  13    |   700   |   0.000031   |     -      |     -     |   3.39   \n",
            "  13    |   720   |   0.032057   |     -      |     -     |   3.39   \n",
            "  13    |   740   |   0.000028   |     -      |     -     |   3.39   \n",
            "  13    |   760   |   0.002739   |     -      |     -     |   3.39   \n",
            "  13    |   780   |   0.044717   |     -      |     -     |   3.39   \n",
            "  13    |   800   |   0.000166   |     -      |     -     |   3.39   \n",
            "  13    |   820   |   0.001431   |     -      |     -     |   3.39   \n",
            "  13    |   840   |   0.012630   |     -      |     -     |   3.39   \n",
            "  13    |   860   |   0.049139   |     -      |     -     |   3.38   \n",
            "  13    |   880   |   0.000060   |     -      |     -     |   3.39   \n",
            "  13    |   900   |   0.019613   |     -      |     -     |   3.39   \n",
            "  13    |   920   |   0.000163   |     -      |     -     |   3.39   \n",
            "  13    |   940   |   0.000049   |     -      |     -     |   3.39   \n",
            "  13    |   960   |   0.009707   |     -      |     -     |   3.39   \n",
            "  13    |   980   |   0.000039   |     -      |     -     |   3.39   \n",
            "  13    |   999   |   0.000067   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  13    |    -    |   0.007092   |  1.275632  |   85.45   |  184.21  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  14    |   20    |   0.002471   |     -      |     -     |   3.56   \n",
            "  14    |   40    |   0.001708   |     -      |     -     |   3.39   \n",
            "  14    |   60    |   0.000039   |     -      |     -     |   3.40   \n",
            "  14    |   80    |   0.000608   |     -      |     -     |   3.40   \n",
            "  14    |   100   |   0.000033   |     -      |     -     |   3.39   \n",
            "  14    |   120   |   0.000030   |     -      |     -     |   3.39   \n",
            "  14    |   140   |   0.003263   |     -      |     -     |   3.38   \n",
            "  14    |   160   |   0.000027   |     -      |     -     |   3.39   \n",
            "  14    |   180   |   0.000028   |     -      |     -     |   3.39   \n",
            "  14    |   200   |   0.008500   |     -      |     -     |   3.39   \n",
            "  14    |   220   |   0.000064   |     -      |     -     |   3.39   \n",
            "  14    |   240   |   0.022894   |     -      |     -     |   3.39   \n",
            "  14    |   260   |   0.000049   |     -      |     -     |   3.39   \n",
            "  14    |   280   |   0.000047   |     -      |     -     |   3.39   \n",
            "  14    |   300   |   0.001577   |     -      |     -     |   3.39   \n",
            "  14    |   320   |   0.004894   |     -      |     -     |   3.40   \n",
            "  14    |   340   |   0.000036   |     -      |     -     |   3.39   \n",
            "  14    |   360   |   0.000036   |     -      |     -     |   3.38   \n",
            "  14    |   380   |   0.000253   |     -      |     -     |   3.39   \n",
            "  14    |   400   |   0.031599   |     -      |     -     |   3.39   \n",
            "  14    |   420   |   0.016927   |     -      |     -     |   3.39   \n",
            "  14    |   440   |   0.003537   |     -      |     -     |   3.38   \n",
            "  14    |   460   |   0.002968   |     -      |     -     |   3.38   \n",
            "  14    |   480   |   0.013958   |     -      |     -     |   3.39   \n",
            "  14    |   500   |   0.002912   |     -      |     -     |   3.39   \n",
            "  14    |   520   |   0.029405   |     -      |     -     |   3.39   \n",
            "  14    |   540   |   0.000031   |     -      |     -     |   3.38   \n",
            "  14    |   560   |   0.000030   |     -      |     -     |   3.39   \n",
            "  14    |   580   |   0.019102   |     -      |     -     |   3.39   \n",
            "  14    |   600   |   0.000036   |     -      |     -     |   3.39   \n",
            "  14    |   620   |   0.000032   |     -      |     -     |   3.39   \n",
            "  14    |   640   |   0.000055   |     -      |     -     |   3.39   \n",
            "  14    |   660   |   0.000092   |     -      |     -     |   3.40   \n",
            "  14    |   680   |   0.009973   |     -      |     -     |   3.39   \n",
            "  14    |   700   |   0.000051   |     -      |     -     |   3.39   \n",
            "  14    |   720   |   0.023797   |     -      |     -     |   3.39   \n",
            "  14    |   740   |   0.022615   |     -      |     -     |   3.39   \n",
            "  14    |   760   |   0.000028   |     -      |     -     |   3.39   \n",
            "  14    |   780   |   0.021017   |     -      |     -     |   3.38   \n",
            "  14    |   800   |   0.000039   |     -      |     -     |   3.39   \n",
            "  14    |   820   |   0.010218   |     -      |     -     |   3.39   \n",
            "  14    |   840   |   0.000099   |     -      |     -     |   3.39   \n",
            "  14    |   860   |   0.000042   |     -      |     -     |   3.39   \n",
            "  14    |   880   |   0.001945   |     -      |     -     |   3.39   \n",
            "  14    |   900   |   0.017793   |     -      |     -     |   3.39   \n",
            "  14    |   920   |   0.000045   |     -      |     -     |   3.39   \n",
            "  14    |   940   |   0.000034   |     -      |     -     |   3.40   \n",
            "  14    |   960   |   0.000025   |     -      |     -     |   3.39   \n",
            "  14    |   980   |   0.000028   |     -      |     -     |   3.39   \n",
            "  14    |   999   |   0.018932   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  14    |    -    |   0.005862   |  1.403367  |   84.95   |  184.20  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  15    |   20    |   0.000034   |     -      |     -     |   3.57   \n",
            "  15    |   40    |   0.000054   |     -      |     -     |   3.39   \n",
            "  15    |   60    |   0.005346   |     -      |     -     |   3.39   \n",
            "  15    |   80    |   0.002545   |     -      |     -     |   3.38   \n",
            "  15    |   100   |   0.004145   |     -      |     -     |   3.39   \n",
            "  15    |   120   |   0.000033   |     -      |     -     |   3.39   \n",
            "  15    |   140   |   0.040487   |     -      |     -     |   3.39   \n",
            "  15    |   160   |   0.000099   |     -      |     -     |   3.39   \n",
            "  15    |   180   |   0.000291   |     -      |     -     |   3.39   \n",
            "  15    |   200   |   0.000019   |     -      |     -     |   3.39   \n",
            "  15    |   220   |   0.000019   |     -      |     -     |   3.39   \n",
            "  15    |   240   |   0.011864   |     -      |     -     |   3.39   \n",
            "  15    |   260   |   0.022605   |     -      |     -     |   3.40   \n",
            "  15    |   280   |   0.001383   |     -      |     -     |   3.39   \n",
            "  15    |   300   |   0.000028   |     -      |     -     |   3.42   \n",
            "  15    |   320   |   0.000021   |     -      |     -     |   3.39   \n",
            "  15    |   340   |   0.000132   |     -      |     -     |   3.39   \n",
            "  15    |   360   |   0.000155   |     -      |     -     |   3.39   \n",
            "  15    |   380   |   0.001881   |     -      |     -     |   3.38   \n",
            "  15    |   400   |   0.000017   |     -      |     -     |   3.38   \n",
            "  15    |   420   |   0.000124   |     -      |     -     |   3.39   \n",
            "  15    |   440   |   0.024998   |     -      |     -     |   3.39   \n",
            "  15    |   460   |   0.000025   |     -      |     -     |   3.39   \n",
            "  15    |   480   |   0.017193   |     -      |     -     |   3.39   \n",
            "  15    |   500   |   0.000023   |     -      |     -     |   3.39   \n",
            "  15    |   520   |   0.070778   |     -      |     -     |   3.39   \n",
            "  15    |   540   |   0.001966   |     -      |     -     |   3.39   \n",
            "  15    |   560   |   0.001981   |     -      |     -     |   3.40   \n",
            "  15    |   580   |   0.051028   |     -      |     -     |   3.38   \n",
            "  15    |   600   |   0.019268   |     -      |     -     |   3.39   \n",
            "  15    |   620   |   0.019477   |     -      |     -     |   3.39   \n",
            "  15    |   640   |   0.015670   |     -      |     -     |   3.39   \n",
            "  15    |   660   |   0.000197   |     -      |     -     |   3.39   \n",
            "  15    |   680   |   0.000067   |     -      |     -     |   3.39   \n",
            "  15    |   700   |   0.000040   |     -      |     -     |   3.39   \n",
            "  15    |   720   |   0.000082   |     -      |     -     |   3.39   \n",
            "  15    |   740   |   0.022272   |     -      |     -     |   3.39   \n",
            "  15    |   760   |   0.000076   |     -      |     -     |   3.39   \n",
            "  15    |   780   |   0.000703   |     -      |     -     |   3.39   \n",
            "  15    |   800   |   0.000046   |     -      |     -     |   3.40   \n",
            "  15    |   820   |   0.003016   |     -      |     -     |   3.40   \n",
            "  15    |   840   |   0.046245   |     -      |     -     |   3.39   \n",
            "  15    |   860   |   0.015420   |     -      |     -     |   3.40   \n",
            "  15    |   880   |   0.009986   |     -      |     -     |   3.40   \n",
            "  15    |   900   |   0.016930   |     -      |     -     |   3.40   \n",
            "  15    |   920   |   0.000295   |     -      |     -     |   3.40   \n",
            "  15    |   940   |   0.007711   |     -      |     -     |   3.40   \n",
            "  15    |   960   |   0.000068   |     -      |     -     |   3.40   \n",
            "  15    |   980   |   0.000070   |     -      |     -     |   3.40   \n",
            "  15    |   999   |   0.000174   |     -      |     -     |   3.23   \n",
            "----------------------------------------------------------------------\n",
            "  15    |    -    |   0.008742   |  1.273163  |   85.20   |  184.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  16    |   20    |   0.000019   |     -      |     -     |   3.57   \n",
            "  16    |   40    |   0.025483   |     -      |     -     |   3.40   \n",
            "  16    |   60    |   0.006197   |     -      |     -     |   3.39   \n",
            "  16    |   80    |   0.000019   |     -      |     -     |   3.40   \n",
            "  16    |   100   |   0.000070   |     -      |     -     |   3.39   \n",
            "  16    |   120   |   0.000036   |     -      |     -     |   3.39   \n",
            "  16    |   140   |   0.000029   |     -      |     -     |   3.39   \n",
            "  16    |   160   |   0.000021   |     -      |     -     |   3.40   \n",
            "  16    |   180   |   0.002912   |     -      |     -     |   3.40   \n",
            "  16    |   200   |   0.001786   |     -      |     -     |   3.39   \n",
            "  16    |   220   |   0.000023   |     -      |     -     |   3.39   \n",
            "  16    |   240   |   0.000409   |     -      |     -     |   3.39   \n",
            "  16    |   260   |   0.000026   |     -      |     -     |   3.40   \n",
            "  16    |   280   |   0.005115   |     -      |     -     |   3.39   \n",
            "  16    |   300   |   0.000019   |     -      |     -     |   3.39   \n",
            "  16    |   320   |   0.004256   |     -      |     -     |   3.39   \n",
            "  16    |   340   |   0.000022   |     -      |     -     |   3.40   \n",
            "  16    |   360   |   0.040224   |     -      |     -     |   3.39   \n",
            "  16    |   380   |   0.006085   |     -      |     -     |   3.39   \n",
            "  16    |   400   |   0.000856   |     -      |     -     |   3.40   \n",
            "  16    |   420   |   0.002031   |     -      |     -     |   3.40   \n",
            "  16    |   440   |   0.002932   |     -      |     -     |   3.40   \n",
            "  16    |   460   |   0.000039   |     -      |     -     |   3.40   \n",
            "  16    |   480   |   0.023690   |     -      |     -     |   3.39   \n",
            "  16    |   500   |   0.000023   |     -      |     -     |   3.39   \n",
            "  16    |   520   |   0.000024   |     -      |     -     |   3.39   \n",
            "  16    |   540   |   0.026173   |     -      |     -     |   3.39   \n",
            "  16    |   560   |   0.000035   |     -      |     -     |   3.39   \n",
            "  16    |   580   |   0.000031   |     -      |     -     |   3.39   \n",
            "  16    |   600   |   0.001765   |     -      |     -     |   3.40   \n",
            "  16    |   620   |   0.000018   |     -      |     -     |   3.39   \n",
            "  16    |   640   |   0.002553   |     -      |     -     |   3.39   \n",
            "  16    |   660   |   0.001910   |     -      |     -     |   3.39   \n",
            "  16    |   680   |   0.029082   |     -      |     -     |   3.39   \n",
            "  16    |   700   |   0.000063   |     -      |     -     |   3.39   \n",
            "  16    |   720   |   0.014927   |     -      |     -     |   3.39   \n",
            "  16    |   740   |   0.000059   |     -      |     -     |   3.39   \n",
            "  16    |   760   |   0.006675   |     -      |     -     |   3.39   \n",
            "  16    |   780   |   0.012754   |     -      |     -     |   3.39   \n",
            "  16    |   800   |   0.000031   |     -      |     -     |   3.38   \n",
            "  16    |   820   |   0.000035   |     -      |     -     |   3.39   \n",
            "  16    |   840   |   0.023861   |     -      |     -     |   3.39   \n",
            "  16    |   860   |   0.000050   |     -      |     -     |   3.39   \n",
            "  16    |   880   |   0.000017   |     -      |     -     |   3.39   \n",
            "  16    |   900   |   0.000015   |     -      |     -     |   3.39   \n",
            "  16    |   920   |   0.000014   |     -      |     -     |   3.39   \n",
            "  16    |   940   |   0.001833   |     -      |     -     |   3.39   \n",
            "  16    |   960   |   0.000015   |     -      |     -     |   3.39   \n",
            "  16    |   980   |   0.000016   |     -      |     -     |   3.39   \n",
            "  16    |   999   |   0.000013   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  16    |    -    |   0.004886   |  1.364273  |   85.60   |  184.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  17    |   20    |   0.000012   |     -      |     -     |   3.56   \n",
            "  17    |   40    |   0.001796   |     -      |     -     |   3.39   \n",
            "  17    |   60    |   0.000012   |     -      |     -     |   3.39   \n",
            "  17    |   80    |   0.002738   |     -      |     -     |   3.39   \n",
            "  17    |   100   |   0.000017   |     -      |     -     |   3.39   \n",
            "  17    |   120   |   0.000018   |     -      |     -     |   3.39   \n",
            "  17    |   140   |   0.000014   |     -      |     -     |   3.39   \n",
            "  17    |   160   |   0.000011   |     -      |     -     |   3.39   \n",
            "  17    |   180   |   0.020674   |     -      |     -     |   3.39   \n",
            "  17    |   200   |   0.000074   |     -      |     -     |   3.38   \n",
            "  17    |   220   |   0.000015   |     -      |     -     |   3.38   \n",
            "  17    |   240   |   0.000015   |     -      |     -     |   3.38   \n",
            "  17    |   260   |   0.000016   |     -      |     -     |   3.38   \n",
            "  17    |   280   |   0.000015   |     -      |     -     |   3.39   \n",
            "  17    |   300   |   0.000037   |     -      |     -     |   3.39   \n",
            "  17    |   320   |   0.000013   |     -      |     -     |   3.40   \n",
            "  17    |   340   |   0.000022   |     -      |     -     |   3.38   \n",
            "  17    |   360   |   0.000014   |     -      |     -     |   3.39   \n",
            "  17    |   380   |   0.000013   |     -      |     -     |   3.39   \n",
            "  17    |   400   |   0.000012   |     -      |     -     |   3.39   \n",
            "  17    |   420   |   0.000011   |     -      |     -     |   3.39   \n",
            "  17    |   440   |   0.001560   |     -      |     -     |   3.39   \n",
            "  17    |   460   |   0.015005   |     -      |     -     |   3.39   \n",
            "  17    |   480   |   0.000011   |     -      |     -     |   3.39   \n",
            "  17    |   500   |   0.000012   |     -      |     -     |   3.39   \n",
            "  17    |   520   |   0.013979   |     -      |     -     |   3.39   \n",
            "  17    |   540   |   0.000011   |     -      |     -     |   3.40   \n",
            "  17    |   560   |   0.003165   |     -      |     -     |   3.38   \n",
            "  17    |   580   |   0.000012   |     -      |     -     |   3.39   \n",
            "  17    |   600   |   0.014737   |     -      |     -     |   3.40   \n",
            "  17    |   620   |   0.000012   |     -      |     -     |   3.39   \n",
            "  17    |   640   |   0.000011   |     -      |     -     |   3.39   \n",
            "  17    |   660   |   0.000010   |     -      |     -     |   3.41   \n",
            "  17    |   680   |   0.000013   |     -      |     -     |   3.39   \n",
            "  17    |   700   |   0.000014   |     -      |     -     |   3.39   \n",
            "  17    |   720   |   0.000023   |     -      |     -     |   3.39   \n",
            "  17    |   740   |   0.001516   |     -      |     -     |   3.39   \n",
            "  17    |   760   |   0.003242   |     -      |     -     |   3.39   \n",
            "  17    |   780   |   0.000011   |     -      |     -     |   3.38   \n",
            "  17    |   800   |   0.000012   |     -      |     -     |   3.39   \n",
            "  17    |   820   |   0.000011   |     -      |     -     |   3.38   \n",
            "  17    |   840   |   0.000016   |     -      |     -     |   3.39   \n",
            "  17    |   860   |   0.000020   |     -      |     -     |   3.38   \n",
            "  17    |   880   |   0.010838   |     -      |     -     |   3.38   \n",
            "  17    |   900   |   0.001839   |     -      |     -     |   3.39   \n",
            "  17    |   920   |   0.000009   |     -      |     -     |   3.38   \n",
            "  17    |   940   |   0.000021   |     -      |     -     |   3.39   \n",
            "  17    |   960   |   0.002639   |     -      |     -     |   3.38   \n",
            "  17    |   980   |   0.001862   |     -      |     -     |   3.38   \n",
            "  17    |   999   |   0.001882   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  17    |    -    |   0.001959   |  1.428222  |   85.20   |  184.16  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  18    |   20    |   0.000020   |     -      |     -     |   3.57   \n",
            "  18    |   40    |   0.002579   |     -      |     -     |   3.39   \n",
            "  18    |   60    |   0.000010   |     -      |     -     |   3.39   \n",
            "  18    |   80    |   0.000018   |     -      |     -     |   3.39   \n",
            "  18    |   100   |   0.004146   |     -      |     -     |   3.38   \n",
            "  18    |   120   |   0.000010   |     -      |     -     |   3.39   \n",
            "  18    |   140   |   0.000432   |     -      |     -     |   3.38   \n",
            "  18    |   160   |   0.027238   |     -      |     -     |   3.39   \n",
            "  18    |   180   |   0.022114   |     -      |     -     |   3.38   \n",
            "  18    |   200   |   0.000019   |     -      |     -     |   3.39   \n",
            "  18    |   220   |   0.001422   |     -      |     -     |   3.39   \n",
            "  18    |   240   |   0.000011   |     -      |     -     |   3.38   \n",
            "  18    |   260   |   0.000013   |     -      |     -     |   3.38   \n",
            "  18    |   280   |   0.000012   |     -      |     -     |   3.39   \n",
            "  18    |   300   |   0.003726   |     -      |     -     |   3.38   \n",
            "  18    |   320   |   0.001643   |     -      |     -     |   3.39   \n",
            "  18    |   340   |   0.001805   |     -      |     -     |   3.39   \n",
            "  18    |   360   |   0.000012   |     -      |     -     |   3.38   \n",
            "  18    |   380   |   0.017424   |     -      |     -     |   3.39   \n",
            "  18    |   400   |   0.028143   |     -      |     -     |   3.39   \n",
            "  18    |   420   |   0.000013   |     -      |     -     |   3.39   \n",
            "  18    |   440   |   0.000032   |     -      |     -     |   3.39   \n",
            "  18    |   460   |   0.000010   |     -      |     -     |   3.39   \n",
            "  18    |   480   |   0.000011   |     -      |     -     |   3.38   \n",
            "  18    |   500   |   0.000013   |     -      |     -     |   3.39   \n",
            "  18    |   520   |   0.000009   |     -      |     -     |   3.39   \n",
            "  18    |   540   |   0.002080   |     -      |     -     |   3.39   \n",
            "  18    |   560   |   0.000009   |     -      |     -     |   3.38   \n",
            "  18    |   580   |   0.000019   |     -      |     -     |   3.39   \n",
            "  18    |   600   |   0.000009   |     -      |     -     |   3.39   \n",
            "  18    |   620   |   0.000011   |     -      |     -     |   3.38   \n",
            "  18    |   640   |   0.000111   |     -      |     -     |   3.39   \n",
            "  18    |   660   |   0.000012   |     -      |     -     |   3.40   \n",
            "  18    |   680   |   0.056649   |     -      |     -     |   3.39   \n",
            "  18    |   700   |   0.000010   |     -      |     -     |   3.39   \n",
            "  18    |   720   |   0.001406   |     -      |     -     |   3.39   \n",
            "  18    |   740   |   0.000025   |     -      |     -     |   3.39   \n",
            "  18    |   760   |   0.000014   |     -      |     -     |   3.39   \n",
            "  18    |   780   |   0.000012   |     -      |     -     |   3.39   \n",
            "  18    |   800   |   0.000010   |     -      |     -     |   3.39   \n",
            "  18    |   820   |   0.002850   |     -      |     -     |   3.39   \n",
            "  18    |   840   |   0.000013   |     -      |     -     |   3.39   \n",
            "  18    |   860   |   0.000020   |     -      |     -     |   3.39   \n",
            "  18    |   880   |   0.000009   |     -      |     -     |   3.39   \n",
            "  18    |   900   |   0.006301   |     -      |     -     |   3.39   \n",
            "  18    |   920   |   0.003182   |     -      |     -     |   3.39   \n",
            "  18    |   940   |   0.001550   |     -      |     -     |   3.39   \n",
            "  18    |   960   |   0.000016   |     -      |     -     |   3.39   \n",
            "  18    |   980   |   0.000022   |     -      |     -     |   3.39   \n",
            "  18    |   999   |   0.022853   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  18    |    -    |   0.004139   |  1.366691  |   85.15   |  184.17  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  19    |   20    |   0.002731   |     -      |     -     |   3.56   \n",
            "  19    |   40    |   0.000013   |     -      |     -     |   3.39   \n",
            "  19    |   60    |   0.000013   |     -      |     -     |   3.39   \n",
            "  19    |   80    |   0.000021   |     -      |     -     |   3.39   \n",
            "  19    |   100   |   0.000011   |     -      |     -     |   3.39   \n",
            "  19    |   120   |   0.000010   |     -      |     -     |   3.39   \n",
            "  19    |   140   |   0.000889   |     -      |     -     |   3.39   \n",
            "  19    |   160   |   0.000014   |     -      |     -     |   3.39   \n",
            "  19    |   180   |   0.000012   |     -      |     -     |   3.39   \n",
            "  19    |   200   |   0.000010   |     -      |     -     |   3.39   \n",
            "  19    |   220   |   0.000012   |     -      |     -     |   3.38   \n",
            "  19    |   240   |   0.000009   |     -      |     -     |   3.39   \n",
            "  19    |   260   |   0.000013   |     -      |     -     |   3.39   \n",
            "  19    |   280   |   0.001806   |     -      |     -     |   3.39   \n",
            "  19    |   300   |   0.000009   |     -      |     -     |   3.39   \n",
            "  19    |   320   |   0.000014   |     -      |     -     |   3.39   \n",
            "  19    |   340   |   0.000010   |     -      |     -     |   3.39   \n",
            "  19    |   360   |   0.000008   |     -      |     -     |   3.40   \n",
            "  19    |   380   |   0.002569   |     -      |     -     |   3.39   \n",
            "  19    |   400   |   0.005521   |     -      |     -     |   3.39   \n",
            "  19    |   420   |   0.001470   |     -      |     -     |   3.39   \n",
            "  19    |   440   |   0.000009   |     -      |     -     |   3.39   \n",
            "  19    |   460   |   0.000017   |     -      |     -     |   3.39   \n",
            "  19    |   480   |   0.000010   |     -      |     -     |   3.39   \n",
            "  19    |   500   |   0.000010   |     -      |     -     |   3.39   \n",
            "  19    |   520   |   0.001745   |     -      |     -     |   3.39   \n",
            "  19    |   540   |   0.000021   |     -      |     -     |   3.39   \n",
            "  19    |   560   |   0.000008   |     -      |     -     |   3.39   \n",
            "  19    |   580   |   0.001412   |     -      |     -     |   3.39   \n",
            "  19    |   600   |   0.001748   |     -      |     -     |   3.39   \n",
            "  19    |   620   |   0.000008   |     -      |     -     |   3.39   \n",
            "  19    |   640   |   0.000009   |     -      |     -     |   3.39   \n",
            "  19    |   660   |   0.000008   |     -      |     -     |   3.39   \n",
            "  19    |   680   |   0.000009   |     -      |     -     |   3.39   \n",
            "  19    |   700   |   0.000009   |     -      |     -     |   3.39   \n",
            "  19    |   720   |   0.000067   |     -      |     -     |   3.39   \n",
            "  19    |   740   |   0.000012   |     -      |     -     |   3.39   \n",
            "  19    |   760   |   0.000009   |     -      |     -     |   3.39   \n",
            "  19    |   780   |   0.000011   |     -      |     -     |   3.40   \n",
            "  19    |   800   |   0.000007   |     -      |     -     |   3.40   \n",
            "  19    |   820   |   0.008583   |     -      |     -     |   3.39   \n",
            "  19    |   840   |   0.000023   |     -      |     -     |   3.39   \n",
            "  19    |   860   |   0.005485   |     -      |     -     |   3.39   \n",
            "  19    |   880   |   0.000034   |     -      |     -     |   3.40   \n",
            "  19    |   900   |   0.003426   |     -      |     -     |   3.39   \n",
            "  19    |   920   |   0.000011   |     -      |     -     |   3.39   \n",
            "  19    |   940   |   0.000014   |     -      |     -     |   3.39   \n",
            "  19    |   960   |   0.003384   |     -      |     -     |   3.40   \n",
            "  19    |   980   |   0.000009   |     -      |     -     |   3.40   \n",
            "  19    |   999   |   0.000007   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  19    |    -    |   0.000828   |  1.416800  |   85.38   |  184.33  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  20    |   20    |   0.001698   |     -      |     -     |   3.56   \n",
            "  20    |   40    |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   60    |   0.000014   |     -      |     -     |   3.39   \n",
            "  20    |   80    |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   100   |   0.002339   |     -      |     -     |   3.38   \n",
            "  20    |   120   |   0.000008   |     -      |     -     |   3.38   \n",
            "  20    |   140   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   160   |   0.001735   |     -      |     -     |   3.39   \n",
            "  20    |   180   |   0.000009   |     -      |     -     |   3.39   \n",
            "  20    |   200   |   0.003006   |     -      |     -     |   3.38   \n",
            "  20    |   220   |   0.001387   |     -      |     -     |   3.39   \n",
            "  20    |   240   |   0.000032   |     -      |     -     |   3.38   \n",
            "  20    |   260   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   280   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   300   |   0.000007   |     -      |     -     |   3.40   \n",
            "  20    |   320   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   340   |   0.000778   |     -      |     -     |   3.39   \n",
            "  20    |   360   |   0.000010   |     -      |     -     |   3.39   \n",
            "  20    |   380   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   400   |   0.000006   |     -      |     -     |   3.40   \n",
            "  20    |   420   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   440   |   0.000006   |     -      |     -     |   3.39   \n",
            "  20    |   460   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   480   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   500   |   0.000006   |     -      |     -     |   3.39   \n",
            "  20    |   520   |   0.011692   |     -      |     -     |   3.40   \n",
            "  20    |   540   |   0.000034   |     -      |     -     |   3.39   \n",
            "  20    |   560   |   0.003190   |     -      |     -     |   3.39   \n",
            "  20    |   580   |   0.000006   |     -      |     -     |   3.39   \n",
            "  20    |   600   |   0.000216   |     -      |     -     |   3.39   \n",
            "  20    |   620   |   0.003715   |     -      |     -     |   3.40   \n",
            "  20    |   640   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   660   |   0.002776   |     -      |     -     |   3.39   \n",
            "  20    |   680   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   700   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   720   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   740   |   0.000006   |     -      |     -     |   3.39   \n",
            "  20    |   760   |   0.000334   |     -      |     -     |   3.39   \n",
            "  20    |   780   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   800   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   820   |   0.016448   |     -      |     -     |   3.39   \n",
            "  20    |   840   |   0.000006   |     -      |     -     |   3.39   \n",
            "  20    |   860   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   880   |   0.014724   |     -      |     -     |   3.39   \n",
            "  20    |   900   |   0.000008   |     -      |     -     |   3.39   \n",
            "  20    |   920   |   0.001352   |     -      |     -     |   3.39   \n",
            "  20    |   940   |   0.000007   |     -      |     -     |   3.38   \n",
            "  20    |   960   |   0.000007   |     -      |     -     |   3.39   \n",
            "  20    |   980   |   0.000006   |     -      |     -     |   3.39   \n",
            "  20    |   999   |   0.000008   |     -      |     -     |   3.22   \n",
            "----------------------------------------------------------------------\n",
            "  20    |    -    |   0.001316   |  1.443972  |   85.35   |  184.20  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n",
            "Evaluation Loss: 1.4439717771422182, Evaluation Accuracy: 85.35\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import nltk\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data, tokenizer):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=140,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "\n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.stack(input_ids)\n",
        "    attention_masks = torch.stack(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def load_data(path):\n",
        "    data = pd.read_csv(path).drop(columns=['Unnamed: 0', \"post_created\", \"user_id\"])\n",
        "\n",
        "    X = data.post_text.values\n",
        "    y = data.label.values\n",
        "\n",
        "    X_train, X_val, y_train, y_val =\\\n",
        "        train_test_split(X, y, test_size=0.2, random_state=666)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "        print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    else:\n",
        "        print('No GPU available, using the CPU instead.')\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    nltk.download(\"stopwords\")\n",
        "\n",
        "    # Preprocess text\n",
        "    X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
        "    X_val_preprocessed = np.array([text_preprocessing(text) for text in X_val])\n",
        "\n",
        "    return X_train_preprocessed, X_val_preprocessed, y_train, y_val\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out),\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        input_ids, attention_mask = input_ids.squeeze(), attention_mask.squeeze()\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def initialize_model(epochs, dataset_size):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = dataset_size * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, optimizer=None, scheduler=None):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits.squeeze(), b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "def main():\n",
        "    path = \"/content/Mental-Health-Twitter.csv\"\n",
        "    X_train, X_val, y_train, y_val = load_data(path)\n",
        "\n",
        "    # Load the BERT tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "    # Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "    train_inputs, train_masks = preprocessing_for_bert(X_train, tokenizer)\n",
        "    val_inputs, val_masks = preprocessing_for_bert(X_val, tokenizer)\n",
        "\n",
        "    # Convert other data types to torch.Tensor\n",
        "    train_labels = torch.tensor(y_train)\n",
        "    val_labels = torch.tensor(y_val)\n",
        "\n",
        "    # For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "    batch_size = 16\n",
        "\n",
        "    # Create the DataLoader for our training set\n",
        "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Create the DataLoader for our validation set\n",
        "    val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "    val_sampler = SequentialSampler(val_data)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "    set_seed(8675309)    # Set seed for reproducibility\n",
        "    bert_classifier, optimizer, scheduler = initialize_model(epochs=20, dataset_size=len(train_dataloader))\n",
        "    train(bert_classifier, train_dataloader, val_dataloader, epochs=20, evaluation=True,  optimizer=optimizer, scheduler=scheduler)\n",
        "    val_loss, val_accuracy = evaluate(bert_classifier, val_dataloader)\n",
        "    print(f\"Evaluation Loss: {val_loss}, Evaluation Accuracy: {val_accuracy}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to Extract Encoded Vectors and Save as CSV"
      ],
      "metadata": {
        "id": "3Pu06WPhOyr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Custom BERT Classifier (Ensure model initialization)\n",
        "class BertClassifier(torch.nn.Module):\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        # Freeze BERT layers if needed\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.fc = torch.nn.Linear(self.bert.config.hidden_size, 2)  # Assuming binary classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]  # Extract CLS token\n",
        "        return self.fc(cls_output)\n",
        "\n",
        "# Function to preprocess text for BERT\n",
        "def preprocessing_for_bert(texts, tokenizer, max_length=128):\n",
        "    \"\"\"Tokenize text data for BERT\"\"\"\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return encodings[\"input_ids\"], encodings[\"attention_mask\"]\n",
        "\n",
        "# Function to extract embeddings\n",
        "def get_encoded_vectors(model, dataloader, device):\n",
        "    \"\"\"Extract encoded vectors (embeddings) from the BERT model.\"\"\"\n",
        "    model.eval()\n",
        "    encoded_vectors = []\n",
        "    labels = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        # Move batch to the specified device\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.bert(input_ids=b_input_ids, attention_mask=b_attn_mask)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Extract CLS token\n",
        "\n",
        "        encoded_vectors.extend(cls_embeddings)\n",
        "        labels.extend(b_labels.cpu().numpy())\n",
        "\n",
        "    return np.array(encoded_vectors), np.array(labels)\n",
        "\n",
        "# Function to save vectors\n",
        "def save_vectors_to_csv(encoded_vectors, labels, output_path):\n",
        "    \"\"\"Save encoded vectors and labels to a CSV file.\"\"\"\n",
        "    df = pd.DataFrame(encoded_vectors)\n",
        "    df['label'] = labels\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Encoded vectors and labels saved to {output_path}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load dataset\n",
        "    path = \"/content/Mental-Health-Twitter.csv\"\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Debugging: Print column names\n",
        "    print(\"Dataset columns:\", df.columns)\n",
        "\n",
        "    # Use 'post_text' instead of 'text'\n",
        "    X = df[\"post_text\"]\n",
        "    y = df[\"label\"]\n",
        "\n",
        "    # Split dataset\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Load tokenizer (with error handling)\n",
        "    try:\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading tokenizer: {e}\")\n",
        "        exit()\n",
        "\n",
        "    # Preprocess text\n",
        "    train_inputs, train_masks = preprocessing_for_bert(X_train, tokenizer)\n",
        "    train_labels = torch.tensor(y_train.values, dtype=torch.long)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "    train_dataloader = DataLoader(train_data, batch_size=16, sampler=SequentialSampler(train_data))\n",
        "\n",
        "    # Initialize model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    bert_classifier = BertClassifier(freeze_bert=False).to(device)\n",
        "\n",
        "    # Extract encoded vectors\n",
        "    encoded_vectors, labels = get_encoded_vectors(bert_classifier, train_dataloader, device)\n",
        "\n",
        "    # Save encoded vectors\n",
        "    output_path = \"/content/encoded_vectors_with_labels.csv\"\n",
        "    save_vectors_to_csv(encoded_vectors, labels, output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyh4aomhO0jU",
        "outputId": "c7f7213c-f3ce-4526-b5a3-11084c8080a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset columns: Index(['Unnamed: 0', 'post_id', 'post_created', 'post_text', 'user_id',\n",
            "       'followers', 'friends', 'favourites', 'statuses', 'retweets', 'label'],\n",
            "      dtype='object')\n",
            "Encoded vectors and labels saved to /content/encoded_vectors_with_labels.csv\n"
          ]
        }
      ]
    }
  ]
}