{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDwxS06HuFeK",
        "outputId": "e2747a13-daeb-4427-bc1d-bba1b7d14f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your file on Google Drive\n",
        "file_path = \"/content/drive/My Drive/merged_tensors_with_labels.csv\"\n",
        "\n",
        "# Copy the file to Colab under the /content directory\n",
        "!cp \"{file_path}\" /content\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/merged_tensors_with_labels.csv\")\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaEygsX7uV4_",
        "outputId": "9a326ec9-bf95-41a0-aa0b-6ba06daf0c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.788955 -0.452171 -0.718902  0.524362  0.407345 -0.054561  0.599061   \n",
            "1 -0.786391 -0.536763 -0.928366  0.635211  0.677996 -0.164220  0.391323   \n",
            "2 -0.760979 -0.356124 -0.678704  0.650039  0.453287 -0.208375  0.471421   \n",
            "3 -0.645143 -0.442135 -0.855603  0.572795  0.629087 -0.262791  0.218573   \n",
            "4 -0.715979 -0.244338 -0.451217  0.467052  0.265069 -0.223246 -0.013612   \n",
            "\n",
            "          7         8         9  ...       759       760       761       762  \\\n",
            "0  0.322636 -0.314898 -0.999944  ...  0.029673  0.846054  0.820441  0.263943   \n",
            "1  0.416578 -0.727519 -0.999947  ... -0.129403  0.900940  0.696012  0.549645   \n",
            "2  0.159647 -0.395316 -0.999743  ...  0.439547  0.853939  0.784838  0.883011   \n",
            "3  0.249878 -0.622201 -0.999599  ...  0.541194  0.944661  0.662793  0.681176   \n",
            "4  0.125522 -0.200415 -0.999057  ...  0.191682  0.713078  0.695555  0.938667   \n",
            "\n",
            "        763       764       765       766       767  is_depression  \n",
            "0  0.345332  0.482984 -0.372246 -0.635277  0.699350              1  \n",
            "1 -0.077668  0.599802 -0.796655 -0.683269  0.622754              1  \n",
            "2  0.568982  0.452909 -0.571980 -0.646512  0.888765              1  \n",
            "3  0.400102  0.513169 -0.658904 -0.574159  0.832582              1  \n",
            "4  0.679499  0.416515 -0.203758 -0.548361  0.812973              1  \n",
            "\n",
            "[5 rows x 769 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Load the CSV file from /content\n",
        "file_path = \"/content/merged_tensors_with_labels.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Base directory to save bar graph images\n",
        "output_base_dir = \"/content/bargraphs\"\n",
        "\n",
        "# Remove the bargraphs folder if it exists, then create a new one\n",
        "if os.path.exists(output_base_dir):\n",
        "    shutil.rmtree(output_base_dir)  # Delete the folder\n",
        "os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "# Function to generate and save bar graph images with a dark background and contrasting colors\n",
        "def generate_bar_graph(vector, file_name):\n",
        "    # Set a dark background for the plot (black background)\n",
        "    plt.style.use('dark_background')\n",
        "\n",
        "    # Downsample the vector to reduce the number of bars (e.g., every 10th value)\n",
        "    vector = vector[::10]  # Select every 10th value (this reduces the number of bars)\n",
        "\n",
        "    # Create random colors for each bar (bright colors for contrast)\n",
        "    colors = [plt.cm.plasma(random.random()) for _ in range(len(vector))]  # Using the 'plasma' colormap for bright colors\n",
        "\n",
        "    # Set the figure size to smaller dimensions\n",
        "    plt.figure(figsize=(4, 2))  # Smaller output dimensions (width x height)\n",
        "\n",
        "    # Create a bar plot\n",
        "    plt.bar(range(len(vector)), vector, color=colors)  # Assign random colors\n",
        "    plt.axis('off')  # Remove axis\n",
        "    plt.gca().set_frame_on(False)  # Remove the frame around the graph\n",
        "\n",
        "    # Save the image at a much lower DPI for faster image generation\n",
        "    plt.savefig(file_name, bbox_inches='tight', pad_inches=0, dpi=50)  # Further reduced DPI for faster rendering\n",
        "    plt.close()\n",
        "\n",
        "# Generate bar graphs for each vector in the DataFrame and save based on label\n",
        "for idx, row in df.iterrows():\n",
        "    vector = row[:768].values  # Assuming first 768 columns are features\n",
        "    label = row['is_depression']  # Assuming 'is_depression' is the label column\n",
        "\n",
        "    # Define directory based on label (0 or 1)\n",
        "    label_dir = os.path.join(output_base_dir, str(label))\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "    # Generate file path and save bar graph\n",
        "    file_name = os.path.join(label_dir, f\"bargraph_{idx}.png\")\n",
        "    generate_bar_graph(vector, file_name)\n",
        "\n",
        "print(\"Bar graphs generated with optimized performance (faster and smaller) under:\", output_base_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thQPBxalwJri",
        "outputId": "f322b686-c521-420d-96b6-d9f69192a303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bar graphs generated with optimized performance (faster and smaller) under: /content/bargraphs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the output directory\n",
        "output_base_dir = \"/content/bargraphs\"\n",
        "zip_path = \"/content/bargraphs.zip\"\n",
        "\n",
        "# Zip the 'bargraphs' folder\n",
        "shutil.make_archive(output_base_dir, 'zip', output_base_dir)\n",
        "\n",
        "print(\"Bargraphs have been zipped and saved at:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vaq0YcJA-W7",
        "outputId": "fc49d784-d0d5-4ceb-ff7a-29d9f865e7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bargraphs have been zipped and saved at: /content/bargraphs.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Load the CSV file from /content\n",
        "file_path = \"/content/merged_tensors_with_labels.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Base directory to save heatmap images\n",
        "output_base_dir = \"/content/heatmaps\"\n",
        "\n",
        "# Remove the heatmaps folder if it exists, then create a new one\n",
        "if os.path.exists(output_base_dir):\n",
        "    shutil.rmtree(output_base_dir)  # Delete the folder\n",
        "os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "# Create a custom colormap (yellow -> black -> purple)\n",
        "cmap = LinearSegmentedColormap.from_list(\"yellow_black_purple\", [\"yellow\", \"black\", \"purple\"])\n",
        "\n",
        "# Function to generate and save heatmap images\n",
        "def generate_heatmap(vector, file_name):\n",
        "    # Pad the vector to 784 elements\n",
        "    padded_vector = np.pad(vector, (0, 784 - len(vector)), mode='constant')\n",
        "    reshaped_vector = padded_vector.reshape((28, 28))\n",
        "\n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(2, 2))  # Small size for quick generation\n",
        "    plt.imshow(reshaped_vector, cmap=cmap, aspect='auto')\n",
        "    plt.axis('off')  # Remove axis\n",
        "    plt.savefig(file_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "# Generate heatmaps for each vector in the DataFrame and save based on label\n",
        "for idx, row in df.iterrows():\n",
        "    vector = row[:768].values  # Assuming first 768 columns are features\n",
        "    label = row['is_depression']  # Assuming 'is_depression' is the label column\n",
        "\n",
        "    # Define directory based on label (0 or 1)\n",
        "    label_dir = os.path.join(output_base_dir, str(label))\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "    # Generate file path and save heatmap\n",
        "    file_name = os.path.join(label_dir, f\"heatmap_{idx}.png\")\n",
        "    generate_heatmap(vector, file_name)\n",
        "\n",
        "print(\"Heatmaps generated and saved in label-specific folders under:\", output_base_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSgv9FxRd0ha",
        "outputId": "fcdf232b-da6d-4bff-c7aa-ecf7dfda7e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heatmaps generated and saved in label-specific folders under: /content/heatmaps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the output directory\n",
        "output_base_dir = \"/content/heatmaps\"\n",
        "zip_path = \"/content/heatmaps.zip\"\n",
        "\n",
        "# Zip the 'heatmaps' folder\n",
        "shutil.make_archive(output_base_dir, 'zip', output_base_dir)\n",
        "\n",
        "print(\"Heatmaps have been zipped and saved at:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axABrsBH17zD",
        "outputId": "e2841ddb-948b-4f1a-8ae9-be9512785f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heatmaps have been zipped and saved at: /content/heatmaps.zip\n"
          ]
        }
      ]
    }
  ]
}